{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Wrangling with BeautifulSoup, NLTK and spaCy\n",
    "\n",
    "**pip install bs4 nltk spacy textblob**\n",
    "\n",
    "Sources:\n",
    "\n",
    "- Dipanjan Sarkar, Text Analytics with Python: A Practitioner's Guide to Natural Language Processing, 3. Processing and Understanding Text, https://learning.oreilly.com/library/view/text-analytics-with/9781484243541/html/427287_2_En_3_Chapter.xhtml\n",
    "\n",
    "- Steven Bird, Ewan Klein, Edward Loper, Natural Language Processing with Python, Chapter 3. Processing Raw Text, https://learning.oreilly.com/library/view/natural-language-processing/9780596803346/ch03.html#sec-accessing-text\n",
    "\n",
    "Github:\n",
    "\n",
    "Text Analytics with Python - 2nd Edition, \n",
    "A Practitioner's Guide to Natural Language Processing, Ch03 - Processing and Understanding Text, https://github.com/dipanjanS/text-analytics-with-python/tree/master/New-Second-Edition\n",
    "\n",
    "NLTK How-To:\n",
    "\n",
    "https://www.nltk.org/howto.html\n",
    "\n",
    "spaCy:\n",
    "\n",
    "https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjack6/GSU_Spring2025/MSA8700/venv_rag/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'gin-top: 0;\\r\\n    margin-bottom: 0;\\r\\n}\\r\\n#pg-header #pg-machine-header strong {\\r\\n    font-weight: normal;\\r\\n}\\r\\n#pg-header #pg-start-separator, #pg-footer #pg-end-separator {\\r\\n    margin-bottom: 3em;\\r\\n    margin-left: 0;\\r\\n    margin-right: auto;\\r\\n    margin-top: 2em;\\r\\n    text-align: center\\r\\n}\\r\\n\\r\\n    .xhtml_center {text-align: center; display: block;}\\r\\n    .xhtml_center table {\\r\\n        display: table;\\r\\n        text-align: left;\\r\\n        margin-left: auto;\\r\\n        margin-right: auto;\\r\\n        }</style><title>The Project Gutenberg eBook of The Bible, King James version, Book 1: Genesis, by Anonymous</title><style>/* ************************************************************************\\r\\n * classless css copied from https://www.pgdp.net/wiki/CSS_Cookbook/Styles\\r\\n * ********************************************************************** */\\r\\n/* ************************************************************************\\r\\n * set the body margins to allow whitespace along sides of window\\r\\n * ******************************************'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get('http://www.gutenberg.org/cache/epub/8001/pg8001.html')\n",
    "content = data.content\n",
    "print(content[1163:2200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aylor in November 2002.\n",
      "Book 01        Genesis\n",
      "01:001:001 In the beginning God created the heaven and the earth.\n",
      "01:001:002 And the earth was without form, and void; and darkness was\n",
      "           upon the face of the deep. And the Spirit of God moved upon\n",
      "           the face of the waters.\n",
      "01:001:003 And God said, Let there be light: and there was light.\n",
      "01:001:004 And God saw the light, that it was good: and God divided the\n",
      "           light from the darkness.\n",
      "01:001:005 And God called the light Day, and the darkness he called\n",
      "           Night. And the evening and the morning were the first day.\n",
      "01:001:006 And God said, Let there be a firmament in the midst of the\n",
      "           waters, and let it divide the waters from the waters.\n",
      "01:001:007 And God made the firmament, and divided the waters which were\n",
      "           under the firmament from the waters which were above the\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "clean_content = strip_html_tags(content)\n",
    "print(clean_content[1163:2045])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/mjack6/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading text corpora\n",
    "alice = nltk.corpus.gutenberg.raw('carroll-alice.txt')\n",
    "sample_text = (\"US unveils world's most powerful supercomputer, beats China. \" \n",
    "               \"The US has unveiled the world's most powerful supercomputer called 'Summit', \" \n",
    "               \"beating the previous record-holder China's Sunway TaihuLight. With a peak performance \"\n",
    "               \"of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, \"\n",
    "               \"which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, \"\n",
    "               \"which reportedly take up the size of two tennis courts.\")\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144395"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total characters in Alice in Wonderland\n",
    "len(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I. Down the Rabbit-Hole\\n\\nAlice was\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 100 characters in the corpus\n",
    "alice[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in sample_text: 4\n",
      "Sample text sentences :-\n",
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n",
      "\n",
      "Total sentences in alice: 1625\n",
      "First 5 sentences in alice:-\n",
      "[\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I.\"\n",
      " \"Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought Alice 'without pictures or\\nconversation?'\"\n",
      " 'So she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.'\n",
      " \"There was nothing so VERY remarkable in that; nor did Alice think it so\\nVERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\"\n",
      " 'Oh dear!']\n"
     ]
    }
   ],
   "source": [
    "default_st = nltk.sent_tokenize\n",
    "alice_sentences = default_st(text=alice)\n",
    "sample_sentences = default_st(text=sample_text)\n",
    "\n",
    "print('Total sentences in sample_text:', len(sample_sentences))\n",
    "print('Sample text sentences :-')\n",
    "print(np.array(sample_sentences))\n",
    "\n",
    "print('\\nTotal sentences in alice:', len(alice_sentences))\n",
    "print('First 5 sentences in alice:-')\n",
    "print(np.array(alice_sentences[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other languages sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package europarl_raw to\n",
      "[nltk_data]     /Users/mjack6/nltk_data...\n",
      "[nltk_data]   Package europarl_raw is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('europarl_raw')\n",
    "from nltk.corpus import europarl_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157171\n",
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sit\n"
     ]
    }
   ],
   "source": [
    "german_text = nltk.corpus.europarl_raw.german.raw('ep-00-01-17.de')\n",
    "# Total characters in the corpus\n",
    "print(len(german_text))\n",
    "# First 100 characters in the corpus\n",
    "print(german_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default sentence tokenizer \n",
    "german_sentences_def = default_st(text=german_text, language='german')\n",
    "\n",
    "# loading german text tokenizer into a PunktSentenceTokenizer instance  \n",
    "german_tokenizer = nltk.data.load(resource_url='tokenizers/punkt/german.pickle')\n",
    "german_sentences = german_tokenizer.tokenize(german_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.punkt.PunktTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "# verify the type of german_tokenizer\n",
    "# should be PunktSentenceTokenizer\n",
    "print(type(german_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if results of both tokenizers match \n",
    "# should be True\n",
    "print(german_sentences_def == german_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' \\nWiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen , wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe , daß Sie schöne Ferien hatten .'\n",
      " 'Wie Sie feststellen konnten , ist der gefürchtete \" Millenium-Bug \" nicht eingetreten .'\n",
      " 'Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden .'\n",
      " 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen .'\n",
      " 'Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen - , allen Opfern der Stürme , insbesondere in den verschiedenen Ländern der Europäischen Union , in einer Schweigeminute zu gedenken .']\n"
     ]
    }
   ],
   "source": [
    "# print first 5 sentences of the corpus\n",
    "print(np.array(german_sentences[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PunktSentenceTokenizer for sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n"
     ]
    }
   ],
   "source": [
    "punkt_st = nltk.tokenize.PunktSentenceTokenizer()\n",
    "sample_sentences = punkt_st.tokenize(sample_text)\n",
    "print(np.array(sample_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RegexpTokenizer for sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_TOKENS_PATTERN = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = nltk.tokenize.RegexpTokenizer(\n",
    "            pattern=SENTENCE_TOKENS_PATTERN,\n",
    "            gaps=True)\n",
    "sample_sentences = regex_st.tokenize(sample_text)\n",
    "print(np.array(sample_sentences)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight',\n",
       "       '.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_wt = nltk.word_tokenize\n",
    "words = default_wt(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treebank word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway',\n",
       "       'TaihuLight.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank_wt = nltk.TreebankWordTokenizer()\n",
    "words = treebank_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TokTok Word Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'\", 'Summit', \"'\", ',', 'beating',\n",
       "       'the', 'previous', 'record-holder', 'China', \"'\", 's', 'Sunway',\n",
       "       'TaihuLight.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "words = tokenizer.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regexp word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', 's', 'most', 'powerful', 'supercomputer',\n",
       "       'beats', 'China', 'The', 'US', 'has', 'unveiled', 'the', 'world',\n",
       "       's', 'most', 'powerful', 'supercomputer', 'called', 'Summit',\n",
       "       'beating', 'the', 'previous', 'record', 'holder', 'China', 's',\n",
       "       'Sunway', 'TaihuLight', 'With', 'a', 'peak', 'performance', 'of',\n",
       "       '200', '000', 'trillion', 'calculations', 'per', 'second', 'it',\n",
       "       'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight',\n",
       "       'which', 'is', 'capable', 'of', '93', '000', 'trillion',\n",
       "       'calculations', 'per', 'second', 'Summit', 'has', '4', '608',\n",
       "       'servers', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts'], dtype='<U13')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_PATTERN = r'\\w+'        \n",
    "regex_wt = nltk.RegexpTokenizer(pattern=TOKEN_PATTERN,\n",
    "                                gaps=False)\n",
    "words = regex_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', \"world's\", 'most', 'powerful', 'supercomputer,',\n",
       "       'beats', 'China.', 'The', 'US', 'has', 'unveiled', 'the',\n",
       "       \"world's\", 'most', 'powerful', 'supercomputer', 'called',\n",
       "       \"'Summit',\", 'beating', 'the', 'previous', 'record-holder',\n",
       "       \"China's\", 'Sunway', 'TaihuLight.', 'With', 'a', 'peak',\n",
       "       'performance', 'of', '200,000', 'trillion', 'calculations', 'per',\n",
       "       'second,', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as',\n",
       "       'Sunway', 'TaihuLight,', 'which', 'is', 'capable', 'of', '93,000',\n",
       "       'trillion', 'calculations', 'per', 'second.', 'Summit', 'has',\n",
       "       '4,608', 'servers,', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts.'], dtype='<U14')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAP_PATTERN = r'\\s+'        \n",
    "regex_wt = nltk.RegexpTokenizer(pattern=GAP_PATTERN,\n",
    "                                gaps=True)\n",
    "words = regex_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (3, 10), (11, 18), (19, 23), (24, 32), (33, 47), (48, 53), (54, 60), (61, 64), (65, 67), (68, 71), (72, 80), (81, 84), (85, 92), (93, 97), (98, 106), (107, 120), (121, 127), (128, 137), (138, 145), (146, 149), (150, 158), (159, 172), (173, 180), (181, 187), (188, 199), (200, 204), (205, 206), (207, 211), (212, 223), (224, 226), (227, 234), (235, 243), (244, 256), (257, 260), (261, 268), (269, 271), (272, 274), (275, 279), (280, 285), (286, 288), (289, 293), (294, 296), (297, 303), (304, 315), (316, 321), (322, 324), (325, 332), (333, 335), (336, 342), (343, 351), (352, 364), (365, 368), (369, 376), (377, 383), (384, 387), (388, 393), (394, 402), (403, 408), (409, 419), (420, 424), (425, 427), (428, 431), (432, 436), (437, 439), (440, 443), (444, 450), (451, 458)]\n",
      "['US' 'unveils' \"world's\" 'most' 'powerful' 'supercomputer,' 'beats'\n",
      " 'China.' 'The' 'US' 'has' 'unveiled' 'the' \"world's\" 'most' 'powerful'\n",
      " 'supercomputer' 'called' \"'Summit',\" 'beating' 'the' 'previous'\n",
      " 'record-holder' \"China's\" 'Sunway' 'TaihuLight.' 'With' 'a' 'peak'\n",
      " 'performance' 'of' '200,000' 'trillion' 'calculations' 'per' 'second,'\n",
      " 'it' 'is' 'over' 'twice' 'as' 'fast' 'as' 'Sunway' 'TaihuLight,' 'which'\n",
      " 'is' 'capable' 'of' '93,000' 'trillion' 'calculations' 'per' 'second.'\n",
      " 'Summit' 'has' '4,608' 'servers,' 'which' 'reportedly' 'take' 'up' 'the'\n",
      " 'size' 'of' 'two' 'tennis' 'courts.']\n"
     ]
    }
   ],
   "source": [
    "word_indices = list(regex_wt.span_tokenize(sample_text))\n",
    "print(word_indices)\n",
    "print(np.array([sample_text[start:end] for start, end in word_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived regex tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'\", 'Summit', \"',\", 'beating', 'the',\n",
       "       'previous', 'record', '-', 'holder', 'China', \"'\", 's', 'Sunway',\n",
       "       'TaihuLight', '.', 'With', 'a', 'peak', 'performance', 'of', '200',\n",
       "       ',', '000', 'trillion', 'calculations', 'per', 'second', ',', 'it',\n",
       "       'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight',\n",
       "       ',', 'which', 'is', 'capable', 'of', '93', ',', '000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4', ',',\n",
       "       '608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunkt_wt = nltk.WordPunctTokenizer()\n",
    "words = wordpunkt_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', \"world's\", 'most', 'powerful', 'supercomputer,',\n",
       "       'beats', 'China.', 'The', 'US', 'has', 'unveiled', 'the',\n",
       "       \"world's\", 'most', 'powerful', 'supercomputer', 'called',\n",
       "       \"'Summit',\", 'beating', 'the', 'previous', 'record-holder',\n",
       "       \"China's\", 'Sunway', 'TaihuLight.', 'With', 'a', 'peak',\n",
       "       'performance', 'of', '200,000', 'trillion', 'calculations', 'per',\n",
       "       'second,', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as',\n",
       "       'Sunway', 'TaihuLight,', 'which', 'is', 'capable', 'of', '93,000',\n",
       "       'trillion', 'calculations', 'per', 'second.', 'Summit', 'has',\n",
       "       '4,608', 'servers,', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts.'], dtype='<U14')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitespace_wt = nltk.WhitespaceTokenizer()\n",
    "words = whitespace_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Tokenizers with NLTK and spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['US',\n",
       "  'unveils',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'supercomputer',\n",
       "  ',',\n",
       "  'beats',\n",
       "  'China',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'US',\n",
       "  'has',\n",
       "  'unveiled',\n",
       "  'the',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'supercomputer',\n",
       "  'called',\n",
       "  \"'Summit\",\n",
       "  \"'\",\n",
       "  ',',\n",
       "  'beating',\n",
       "  'the',\n",
       "  'previous',\n",
       "  'record-holder',\n",
       "  'China',\n",
       "  \"'s\",\n",
       "  'Sunway',\n",
       "  'TaihuLight',\n",
       "  '.'],\n",
       " ['With',\n",
       "  'a',\n",
       "  'peak',\n",
       "  'performance',\n",
       "  'of',\n",
       "  '200,000',\n",
       "  'trillion',\n",
       "  'calculations',\n",
       "  'per',\n",
       "  'second',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'over',\n",
       "  'twice',\n",
       "  'as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  'Sunway',\n",
       "  'TaihuLight',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'capable',\n",
       "  'of',\n",
       "  '93,000',\n",
       "  'trillion',\n",
       "  'calculations',\n",
       "  'per',\n",
       "  'second',\n",
       "  '.'],\n",
       " ['Summit',\n",
       "  'has',\n",
       "  '4,608',\n",
       "  'servers',\n",
       "  ',',\n",
       "  'which',\n",
       "  'reportedly',\n",
       "  'take',\n",
       "  'up',\n",
       "  'the',\n",
       "  'size',\n",
       "  'of',\n",
       "  'two',\n",
       "  'tennis',\n",
       "  'courts',\n",
       "  '.']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    word_tokens = [nltk.word_tokenize(sentence) for sentence in sentences] \n",
    "    return word_tokens\n",
    "\n",
    "sents = tokenize_text(sample_text)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight',\n",
       "       '.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word for sentence in sents for word in sentence]\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mjack6/GSU_Spring2025/MSA8700/venv_rag/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 33.5 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25h\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/mjack6/GSU_Spring2025/MSA8700/venv_rag/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "text_spacy = nlp(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[US unveils world's most powerful supercomputer, beats China.,\n",
       " The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.,\n",
       " With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.,\n",
       " Summit has 4,608 servers, which reportedly take up the size of two tennis courts.]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = list(text_spacy.sents)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['US',\n",
       "  'unveils',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'supercomputer',\n",
       "  ',',\n",
       "  'beats',\n",
       "  'China',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'US',\n",
       "  'has',\n",
       "  'unveiled',\n",
       "  'the',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'supercomputer',\n",
       "  'called',\n",
       "  \"'\",\n",
       "  'Summit',\n",
       "  \"'\",\n",
       "  ',',\n",
       "  'beating',\n",
       "  'the',\n",
       "  'previous',\n",
       "  'record',\n",
       "  '-',\n",
       "  'holder',\n",
       "  'China',\n",
       "  \"'s\",\n",
       "  'Sunway',\n",
       "  'TaihuLight',\n",
       "  '.'],\n",
       " ['With',\n",
       "  'a',\n",
       "  'peak',\n",
       "  'performance',\n",
       "  'of',\n",
       "  '200,000',\n",
       "  'trillion',\n",
       "  'calculations',\n",
       "  'per',\n",
       "  'second',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'over',\n",
       "  'twice',\n",
       "  'as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  'Sunway',\n",
       "  'TaihuLight',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'capable',\n",
       "  'of',\n",
       "  '93,000',\n",
       "  'trillion',\n",
       "  'calculations',\n",
       "  'per',\n",
       "  'second',\n",
       "  '.'],\n",
       " ['Summit',\n",
       "  'has',\n",
       "  '4,608',\n",
       "  'servers',\n",
       "  ',',\n",
       "  'which',\n",
       "  'reportedly',\n",
       "  'take',\n",
       "  'up',\n",
       "  'the',\n",
       "  'size',\n",
       "  'of',\n",
       "  'two',\n",
       "  'tennis',\n",
       "  'courts',\n",
       "  '.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_words = [[word.text for word in sent] for sent in sents]\n",
    "sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US',\n",
       " 'unveils',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'most',\n",
       " 'powerful',\n",
       " 'supercomputer',\n",
       " ',',\n",
       " 'beats',\n",
       " 'China',\n",
       " '.',\n",
       " 'The',\n",
       " 'US',\n",
       " 'has',\n",
       " 'unveiled',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'most',\n",
       " 'powerful',\n",
       " 'supercomputer',\n",
       " 'called',\n",
       " \"'\",\n",
       " 'Summit',\n",
       " \"'\",\n",
       " ',',\n",
       " 'beating',\n",
       " 'the',\n",
       " 'previous',\n",
       " 'record',\n",
       " '-',\n",
       " 'holder',\n",
       " 'China',\n",
       " \"'s\",\n",
       " 'Sunway',\n",
       " 'TaihuLight',\n",
       " '.',\n",
       " 'With',\n",
       " 'a',\n",
       " 'peak',\n",
       " 'performance',\n",
       " 'of',\n",
       " '200,000',\n",
       " 'trillion',\n",
       " 'calculations',\n",
       " 'per',\n",
       " 'second',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'over',\n",
       " 'twice',\n",
       " 'as',\n",
       " 'fast',\n",
       " 'as',\n",
       " 'Sunway',\n",
       " 'TaihuLight',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'capable',\n",
       " 'of',\n",
       " '93,000',\n",
       " 'trillion',\n",
       " 'calculations',\n",
       " 'per',\n",
       " 'second',\n",
       " '.',\n",
       " 'Summit',\n",
       " 'has',\n",
       " '4,608',\n",
       " 'servers',\n",
       " ',',\n",
       " 'which',\n",
       " 'reportedly',\n",
       " 'take',\n",
       " 'up',\n",
       " 'the',\n",
       " 'size',\n",
       " 'of',\n",
       " 'two',\n",
       " 'tennis',\n",
       " 'courts',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word.text for word in text_spacy]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sómě Áccěntěd těxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contractions import CONTRACTION_MAP\n",
    "import re\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all cannot expand contractions I would think'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"Y'all can't expand contractions I'd think\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox jumped over the big dog'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The quick brown fox jumped over The Big Dog'\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE QUICK BROWN FOX JUMPED OVER THE BIG DOG'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Quick Brown Fox Jumped Over The Big Dog'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting repeating characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Step: 4 Word: finaly\n",
      "Final word: finaly\n"
     ]
    }
   ],
   "source": [
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    "\n",
    "while True:\n",
    "    # remove one repeated character\n",
    "    new_word = repeat_pattern.sub(match_substitution,\n",
    "                                  old_word)\n",
    "    if new_word != old_word:\n",
    "         print('Step: {} Word: {}'.format(step, new_word))\n",
    "         step += 1 # update step\n",
    "         # update old word to last substituted state\n",
    "         old_word = new_word  \n",
    "         continue\n",
    "    else:\n",
    "         print(\"Final word:\", new_word)\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Final correct word: finally\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    " \n",
    "while True:\n",
    "    # check for semantically correct word\n",
    "    if wordnet.synsets(old_word):\n",
    "        print(\"Final correct word:\", old_word)\n",
    "        break\n",
    "    # remove one repeated character\n",
    "    new_word = repeat_pattern.sub(match_substitution,\n",
    "                                  old_word)\n",
    "    if new_word != old_word:\n",
    "        print('Step: {} Word: {}'.format(step, new_word))\n",
    "        step += 1 # update step\n",
    "        # update old word to last substituted state\n",
    "        old_word = new_word  \n",
    "        continue\n",
    "    else:\n",
    "        print(\"Final word:\", new_word)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def remove_repeated_characters(tokens):\n",
    "    repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "    match_substitution = r'\\1\\2\\3'\n",
    "    def replace(old_word):\n",
    "        if wordnet.synsets(old_word):\n",
    "            return old_word\n",
    "        new_word = repeat_pattern.sub(match_substitution, old_word)\n",
    "        return replace(new_word) if new_word != old_word else new_word\n",
    "            \n",
    "    correct_tokens = [replace(word) for word in tokens]\n",
    "    return correct_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My school is really amazing'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = 'My schooool is realllllyyy amaaazingggg'\n",
    "correct_tokens = remove_repeated_characters(nltk.word_tokenize(sample_sentence))\n",
    "' '.join(correct_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 80030),\n",
       " ('of', 40025),\n",
       " ('and', 38313),\n",
       " ('to', 28766),\n",
       " ('in', 22050),\n",
       " ('a', 21155),\n",
       " ('that', 12512),\n",
       " ('he', 12401),\n",
       " ('was', 11410),\n",
       " ('it', 10681)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, collections\n",
    "\n",
    "def tokens(text): \n",
    "    \"\"\"\n",
    "    Get all words from the corpus\n",
    "    \"\"\"\n",
    "    return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "WORDS = tokens(open('data/big.txt').read())\n",
    "WORD_COUNTS = collections.Counter(WORDS)\n",
    "# top 10 words in corpus\n",
    "WORD_COUNTS.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits0(word): \n",
    "    \"\"\"\n",
    "    Return all strings that are zero edits away \n",
    "    from the input word (i.e., the word itself).\n",
    "    \"\"\"\n",
    "    return {word}\n",
    "\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"\"\"\n",
    "    Return all strings that are one edit away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    def splits(word):\n",
    "        \"\"\"\n",
    "        Return a list of all possible (first, rest) pairs \n",
    "        that the input word is made of.\n",
    "        \"\"\"\n",
    "        return [(word[:i], word[i:]) \n",
    "                for i in range(len(word)+1)]\n",
    "                \n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "\n",
    "def edits2(word):\n",
    "    \"\"\"Return all strings that are two edits away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"\"\"\n",
    "    Return the subset of words that are actually \n",
    "    in our WORD_COUNTS dictionary.\n",
    "    \"\"\"\n",
    "    return {w for w in words if w in WORD_COUNTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fianlly'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input word\n",
    "In [409]: word = 'fianlly'\n",
    "\n",
    "# zero edit distance from input word\n",
    "edits0(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns null set since it is not a valid word\n",
    "known(edits0(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afianlly',\n",
       " 'aianlly',\n",
       " 'bfianlly',\n",
       " 'bianlly',\n",
       " 'cfianlly',\n",
       " 'cianlly',\n",
       " 'dfianlly',\n",
       " 'dianlly',\n",
       " 'efianlly',\n",
       " 'eianlly',\n",
       " 'faanlly',\n",
       " 'faianlly',\n",
       " 'fainlly',\n",
       " 'fanlly',\n",
       " 'fbanlly',\n",
       " 'fbianlly',\n",
       " 'fcanlly',\n",
       " 'fcianlly',\n",
       " 'fdanlly',\n",
       " 'fdianlly',\n",
       " 'feanlly',\n",
       " 'feianlly',\n",
       " 'ffanlly',\n",
       " 'ffianlly',\n",
       " 'fganlly',\n",
       " 'fgianlly',\n",
       " 'fhanlly',\n",
       " 'fhianlly',\n",
       " 'fiaally',\n",
       " 'fiaanlly',\n",
       " 'fiablly',\n",
       " 'fiabnlly',\n",
       " 'fiaclly',\n",
       " 'fiacnlly',\n",
       " 'fiadlly',\n",
       " 'fiadnlly',\n",
       " 'fiaelly',\n",
       " 'fiaenlly',\n",
       " 'fiaflly',\n",
       " 'fiafnlly',\n",
       " 'fiaglly',\n",
       " 'fiagnlly',\n",
       " 'fiahlly',\n",
       " 'fiahnlly',\n",
       " 'fiailly',\n",
       " 'fiainlly',\n",
       " 'fiajlly',\n",
       " 'fiajnlly',\n",
       " 'fiaklly',\n",
       " 'fiaknlly',\n",
       " 'fiallly',\n",
       " 'fially',\n",
       " 'fialnlly',\n",
       " 'fialnly',\n",
       " 'fiamlly',\n",
       " 'fiamnlly',\n",
       " 'fianally',\n",
       " 'fianaly',\n",
       " 'fianblly',\n",
       " 'fianbly',\n",
       " 'fianclly',\n",
       " 'fiancly',\n",
       " 'fiandlly',\n",
       " 'fiandly',\n",
       " 'fianelly',\n",
       " 'fianely',\n",
       " 'fianflly',\n",
       " 'fianfly',\n",
       " 'fianglly',\n",
       " 'fiangly',\n",
       " 'fianhlly',\n",
       " 'fianhly',\n",
       " 'fianilly',\n",
       " 'fianily',\n",
       " 'fianjlly',\n",
       " 'fianjly',\n",
       " 'fianklly',\n",
       " 'fiankly',\n",
       " 'fianlaly',\n",
       " 'fianlay',\n",
       " 'fianlbly',\n",
       " 'fianlby',\n",
       " 'fianlcly',\n",
       " 'fianlcy',\n",
       " 'fianldly',\n",
       " 'fianldy',\n",
       " 'fianlely',\n",
       " 'fianley',\n",
       " 'fianlfly',\n",
       " 'fianlfy',\n",
       " 'fianlgly',\n",
       " 'fianlgy',\n",
       " 'fianlhly',\n",
       " 'fianlhy',\n",
       " 'fianlily',\n",
       " 'fianliy',\n",
       " 'fianljly',\n",
       " 'fianljy',\n",
       " 'fianlkly',\n",
       " 'fianlky',\n",
       " 'fianll',\n",
       " 'fianlla',\n",
       " 'fianllay',\n",
       " 'fianllb',\n",
       " 'fianllby',\n",
       " 'fianllc',\n",
       " 'fianllcy',\n",
       " 'fianlld',\n",
       " 'fianlldy',\n",
       " 'fianlle',\n",
       " 'fianlley',\n",
       " 'fianllf',\n",
       " 'fianllfy',\n",
       " 'fianllg',\n",
       " 'fianllgy',\n",
       " 'fianllh',\n",
       " 'fianllhy',\n",
       " 'fianlli',\n",
       " 'fianlliy',\n",
       " 'fianllj',\n",
       " 'fianlljy',\n",
       " 'fianllk',\n",
       " 'fianllky',\n",
       " 'fianlll',\n",
       " 'fianllly',\n",
       " 'fianllm',\n",
       " 'fianllmy',\n",
       " 'fianlln',\n",
       " 'fianllny',\n",
       " 'fianllo',\n",
       " 'fianlloy',\n",
       " 'fianllp',\n",
       " 'fianllpy',\n",
       " 'fianllq',\n",
       " 'fianllqy',\n",
       " 'fianllr',\n",
       " 'fianllry',\n",
       " 'fianlls',\n",
       " 'fianllsy',\n",
       " 'fianllt',\n",
       " 'fianllty',\n",
       " 'fianllu',\n",
       " 'fianlluy',\n",
       " 'fianllv',\n",
       " 'fianllvy',\n",
       " 'fianllw',\n",
       " 'fianllwy',\n",
       " 'fianllx',\n",
       " 'fianllxy',\n",
       " 'fianlly',\n",
       " 'fianllya',\n",
       " 'fianllyb',\n",
       " 'fianllyc',\n",
       " 'fianllyd',\n",
       " 'fianllye',\n",
       " 'fianllyf',\n",
       " 'fianllyg',\n",
       " 'fianllyh',\n",
       " 'fianllyi',\n",
       " 'fianllyj',\n",
       " 'fianllyk',\n",
       " 'fianllyl',\n",
       " 'fianllym',\n",
       " 'fianllyn',\n",
       " 'fianllyo',\n",
       " 'fianllyp',\n",
       " 'fianllyq',\n",
       " 'fianllyr',\n",
       " 'fianllys',\n",
       " 'fianllyt',\n",
       " 'fianllyu',\n",
       " 'fianllyv',\n",
       " 'fianllyw',\n",
       " 'fianllyx',\n",
       " 'fianllyy',\n",
       " 'fianllyz',\n",
       " 'fianllz',\n",
       " 'fianllzy',\n",
       " 'fianlmly',\n",
       " 'fianlmy',\n",
       " 'fianlnly',\n",
       " 'fianlny',\n",
       " 'fianloly',\n",
       " 'fianloy',\n",
       " 'fianlply',\n",
       " 'fianlpy',\n",
       " 'fianlqly',\n",
       " 'fianlqy',\n",
       " 'fianlrly',\n",
       " 'fianlry',\n",
       " 'fianlsly',\n",
       " 'fianlsy',\n",
       " 'fianltly',\n",
       " 'fianlty',\n",
       " 'fianluly',\n",
       " 'fianluy',\n",
       " 'fianlvly',\n",
       " 'fianlvy',\n",
       " 'fianlwly',\n",
       " 'fianlwy',\n",
       " 'fianlxly',\n",
       " 'fianlxy',\n",
       " 'fianly',\n",
       " 'fianlyl',\n",
       " 'fianlyly',\n",
       " 'fianlyy',\n",
       " 'fianlzly',\n",
       " 'fianlzy',\n",
       " 'fianmlly',\n",
       " 'fianmly',\n",
       " 'fiannlly',\n",
       " 'fiannly',\n",
       " 'fianolly',\n",
       " 'fianoly',\n",
       " 'fianplly',\n",
       " 'fianply',\n",
       " 'fianqlly',\n",
       " 'fianqly',\n",
       " 'fianrlly',\n",
       " 'fianrly',\n",
       " 'fianslly',\n",
       " 'fiansly',\n",
       " 'fiantlly',\n",
       " 'fiantly',\n",
       " 'fianully',\n",
       " 'fianuly',\n",
       " 'fianvlly',\n",
       " 'fianvly',\n",
       " 'fianwlly',\n",
       " 'fianwly',\n",
       " 'fianxlly',\n",
       " 'fianxly',\n",
       " 'fianylly',\n",
       " 'fianyly',\n",
       " 'fianzlly',\n",
       " 'fianzly',\n",
       " 'fiaolly',\n",
       " 'fiaonlly',\n",
       " 'fiaplly',\n",
       " 'fiapnlly',\n",
       " 'fiaqlly',\n",
       " 'fiaqnlly',\n",
       " 'fiarlly',\n",
       " 'fiarnlly',\n",
       " 'fiaslly',\n",
       " 'fiasnlly',\n",
       " 'fiatlly',\n",
       " 'fiatnlly',\n",
       " 'fiaully',\n",
       " 'fiaunlly',\n",
       " 'fiavlly',\n",
       " 'fiavnlly',\n",
       " 'fiawlly',\n",
       " 'fiawnlly',\n",
       " 'fiaxlly',\n",
       " 'fiaxnlly',\n",
       " 'fiaylly',\n",
       " 'fiaynlly',\n",
       " 'fiazlly',\n",
       " 'fiaznlly',\n",
       " 'fibanlly',\n",
       " 'fibnlly',\n",
       " 'ficanlly',\n",
       " 'ficnlly',\n",
       " 'fidanlly',\n",
       " 'fidnlly',\n",
       " 'fieanlly',\n",
       " 'fienlly',\n",
       " 'fifanlly',\n",
       " 'fifnlly',\n",
       " 'figanlly',\n",
       " 'fignlly',\n",
       " 'fihanlly',\n",
       " 'fihnlly',\n",
       " 'fiianlly',\n",
       " 'fiinlly',\n",
       " 'fijanlly',\n",
       " 'fijnlly',\n",
       " 'fikanlly',\n",
       " 'fiknlly',\n",
       " 'filanlly',\n",
       " 'filnlly',\n",
       " 'fimanlly',\n",
       " 'fimnlly',\n",
       " 'finally',\n",
       " 'finanlly',\n",
       " 'finlly',\n",
       " 'finnlly',\n",
       " 'fioanlly',\n",
       " 'fionlly',\n",
       " 'fipanlly',\n",
       " 'fipnlly',\n",
       " 'fiqanlly',\n",
       " 'fiqnlly',\n",
       " 'firanlly',\n",
       " 'firnlly',\n",
       " 'fisanlly',\n",
       " 'fisnlly',\n",
       " 'fitanlly',\n",
       " 'fitnlly',\n",
       " 'fiuanlly',\n",
       " 'fiunlly',\n",
       " 'fivanlly',\n",
       " 'fivnlly',\n",
       " 'fiwanlly',\n",
       " 'fiwnlly',\n",
       " 'fixanlly',\n",
       " 'fixnlly',\n",
       " 'fiyanlly',\n",
       " 'fiynlly',\n",
       " 'fizanlly',\n",
       " 'fiznlly',\n",
       " 'fjanlly',\n",
       " 'fjianlly',\n",
       " 'fkanlly',\n",
       " 'fkianlly',\n",
       " 'flanlly',\n",
       " 'flianlly',\n",
       " 'fmanlly',\n",
       " 'fmianlly',\n",
       " 'fnanlly',\n",
       " 'fnianlly',\n",
       " 'foanlly',\n",
       " 'foianlly',\n",
       " 'fpanlly',\n",
       " 'fpianlly',\n",
       " 'fqanlly',\n",
       " 'fqianlly',\n",
       " 'franlly',\n",
       " 'frianlly',\n",
       " 'fsanlly',\n",
       " 'fsianlly',\n",
       " 'ftanlly',\n",
       " 'ftianlly',\n",
       " 'fuanlly',\n",
       " 'fuianlly',\n",
       " 'fvanlly',\n",
       " 'fvianlly',\n",
       " 'fwanlly',\n",
       " 'fwianlly',\n",
       " 'fxanlly',\n",
       " 'fxianlly',\n",
       " 'fyanlly',\n",
       " 'fyianlly',\n",
       " 'fzanlly',\n",
       " 'fzianlly',\n",
       " 'gfianlly',\n",
       " 'gianlly',\n",
       " 'hfianlly',\n",
       " 'hianlly',\n",
       " 'ianlly',\n",
       " 'ifanlly',\n",
       " 'ifianlly',\n",
       " 'iianlly',\n",
       " 'jfianlly',\n",
       " 'jianlly',\n",
       " 'kfianlly',\n",
       " 'kianlly',\n",
       " 'lfianlly',\n",
       " 'lianlly',\n",
       " 'mfianlly',\n",
       " 'mianlly',\n",
       " 'nfianlly',\n",
       " 'nianlly',\n",
       " 'ofianlly',\n",
       " 'oianlly',\n",
       " 'pfianlly',\n",
       " 'pianlly',\n",
       " 'qfianlly',\n",
       " 'qianlly',\n",
       " 'rfianlly',\n",
       " 'rianlly',\n",
       " 'sfianlly',\n",
       " 'sianlly',\n",
       " 'tfianlly',\n",
       " 'tianlly',\n",
       " 'ufianlly',\n",
       " 'uianlly',\n",
       " 'vfianlly',\n",
       " 'vianlly',\n",
       " 'wfianlly',\n",
       " 'wianlly',\n",
       " 'xfianlly',\n",
       " 'xianlly',\n",
       " 'yfianlly',\n",
       " 'yianlly',\n",
       " 'zfianlly',\n",
       " 'zianlly'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one edit distance from input word\n",
    "edits1(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits1(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fianlxlyz',\n",
       " 'fiasnrly',\n",
       " 'fnanllyk',\n",
       " 'fiadnlay',\n",
       " 'fianltlyq',\n",
       " 'iiafnlly',\n",
       " 'fiaznlky',\n",
       " 'fianlndy',\n",
       " 'fztnlly',\n",
       " 'liadlly',\n",
       " 'fzianllg',\n",
       " 'fgianllvy',\n",
       " 'fianjlkly',\n",
       " 'fianqllyn',\n",
       " 'fkbanlly',\n",
       " 'fiafllo',\n",
       " 'bfianllo',\n",
       " 'fpainlly',\n",
       " 'fiunllt',\n",
       " 'tfiaully',\n",
       " 'fyaslly',\n",
       " 'fienglly',\n",
       " 'rianllr',\n",
       " 'riandly',\n",
       " 'fmianllyh',\n",
       " 'fiagllny',\n",
       " 'kfiaknlly',\n",
       " 'fianyley',\n",
       " 'nianllyr',\n",
       " 'cfianllyk',\n",
       " 'fianlile',\n",
       " 'rianllz',\n",
       " 'fianlloys',\n",
       " 'yianlpy',\n",
       " 'fiqnjlly',\n",
       " 'fiqnllay',\n",
       " 'xfiaxnlly',\n",
       " 'fiqnaly',\n",
       " 'ziaglly',\n",
       " 'uianrly',\n",
       " 'fiaialy',\n",
       " 'fzaglly',\n",
       " 'fipnllyd',\n",
       " 'fcianlqy',\n",
       " 'fikwanlly',\n",
       " 'cfianlcy',\n",
       " 'fihnllvy',\n",
       " 'fsianljly',\n",
       " 'fiagnoly',\n",
       " 'fiavlzly',\n",
       " 'kffanlly',\n",
       " 'fianulf',\n",
       " 'fianloby',\n",
       " 'faanlyly',\n",
       " 'fianbllyl',\n",
       " 'fiagldy',\n",
       " 'fzianllp',\n",
       " 'fiagllay',\n",
       " 'fpaqlly',\n",
       " 'wfianlldy',\n",
       " 'fgianhly',\n",
       " 'fianlleyz',\n",
       " 'fiakllyu',\n",
       " 'fliawlly',\n",
       " 'fihanally',\n",
       " 'fdanlny',\n",
       " 'fignkly',\n",
       " 'fiahrlly',\n",
       " 'frianlely',\n",
       " 'fienluy',\n",
       " 'fianllyjg',\n",
       " 'fianpllyp',\n",
       " 'fianllqyf',\n",
       " 'fiaydnlly',\n",
       " 'fiarilly',\n",
       " 'finnlvly',\n",
       " 'fqionlly',\n",
       " 'fiaxlry',\n",
       " 'fqanhlly',\n",
       " 'fiamllq',\n",
       " 'jfiandly',\n",
       " 'fhiandlly',\n",
       " 'fiuanblly',\n",
       " 'rfianlty',\n",
       " 'limnlly',\n",
       " 'fijanllyn',\n",
       " 'fbeanlly',\n",
       " 'ftianllvy',\n",
       " 'fmianlpy',\n",
       " 'fifnllb',\n",
       " 'fanlzy',\n",
       " 'fiazhnlly',\n",
       " 'iianllu',\n",
       " 'feanvly',\n",
       " 'sfianzly',\n",
       " 'fbianllo',\n",
       " 'fiagkly',\n",
       " 'efiznlly',\n",
       " 'fivanply',\n",
       " 'fikanvly',\n",
       " 'viaclly',\n",
       " 'fianlsyo',\n",
       " 'fiazllu',\n",
       " 'fiazynlly',\n",
       " 'fianlkf',\n",
       " 'fkanlfy',\n",
       " 'gianllyz',\n",
       " 'fiaqwly',\n",
       " 'hfwianlly',\n",
       " 'fciaanlly',\n",
       " 'fiainllly',\n",
       " 'fipanelly',\n",
       " 'zfianqly',\n",
       " 'ppanlly',\n",
       " 'fmvianlly',\n",
       " 'xiaanlly',\n",
       " 'zffianlly',\n",
       " 'xfitnlly',\n",
       " 'iefianlly',\n",
       " 'fqianally',\n",
       " 'fiancdy',\n",
       " 'bfioanlly',\n",
       " 'fiaemlly',\n",
       " 'fianllxuy',\n",
       " 'fiahnsly',\n",
       " 'fjianllj',\n",
       " 'ffiarnlly',\n",
       " 'fjiarlly',\n",
       " 'fianllnuy',\n",
       " 'fianlnfy',\n",
       " 'eianlhly',\n",
       " 'fisanrlly',\n",
       " 'ifianllyd',\n",
       " 'flianll',\n",
       " 'fitnllay',\n",
       " 'fiacllny',\n",
       " 'fiytanlly',\n",
       " 'fijanllf',\n",
       " 'rfiamnlly',\n",
       " 'fdanllyf',\n",
       " 'fiagdnlly',\n",
       " 'fianqlay',\n",
       " 'figarnlly',\n",
       " 'fsiangly',\n",
       " 'fianallby',\n",
       " 'ffoanlly',\n",
       " 'finanllyu',\n",
       " 'fxanlls',\n",
       " 'mienlly',\n",
       " 'iianllyb',\n",
       " 'fianalk',\n",
       " 'foiaunlly',\n",
       " 'fianlylyx',\n",
       " 'fipnllya',\n",
       " 'fmanllfy',\n",
       " 'ojfianlly',\n",
       " 'fiancgy',\n",
       " 'nianxly',\n",
       " 'aianclly',\n",
       " 'fianljw',\n",
       " 'fiatnllyr',\n",
       " 'fianldty',\n",
       " 'fianlkfy',\n",
       " 'ianllx',\n",
       " 'fikxnlly',\n",
       " 'fiaylvy',\n",
       " 'xiknlly',\n",
       " 'fbinally',\n",
       " 'sianwly',\n",
       " 'frianllb',\n",
       " 'ftiantly',\n",
       " 'lfranlly',\n",
       " 'feianmly',\n",
       " 'fdianllyo',\n",
       " 'fiaglnly',\n",
       " 'fitanllmy',\n",
       " 'fsiaglly',\n",
       " 'fkapnlly',\n",
       " 'fianlwyk',\n",
       " 'gianlsy',\n",
       " 'fietanlly',\n",
       " 'fsanllu',\n",
       " 'fianlklyd',\n",
       " 'lbanlly',\n",
       " 'yfbanlly',\n",
       " 'dfiatlly',\n",
       " 'fkatnlly',\n",
       " 'ksfianlly',\n",
       " 'fiaallj',\n",
       " 'ficnlgy',\n",
       " 'fxianuly',\n",
       " 'fiaqnylly',\n",
       " 'fisahnlly',\n",
       " 'fianlxy',\n",
       " 'fiatnlhly',\n",
       " 'sianzly',\n",
       " 'fianlloy',\n",
       " 'fianswly',\n",
       " 'fihglly',\n",
       " 'fiaglljy',\n",
       " 'fviazlly',\n",
       " 'fiaznllyt',\n",
       " 'fianbzy',\n",
       " 'faianltly',\n",
       " 'eiynlly',\n",
       " 'fivanslly',\n",
       " 'fiarlls',\n",
       " 'eianllyu',\n",
       " 'fiatnlzly',\n",
       " 'pianrly',\n",
       " 'fiaalcy',\n",
       " 'finanally',\n",
       " 'fiainlloy',\n",
       " 'vially',\n",
       " 'fianlklyo',\n",
       " 'fjanllo',\n",
       " 'fianllgyv',\n",
       " 'xfiajnlly',\n",
       " 'fpanllny',\n",
       " 'fliazlly',\n",
       " 'tfianllny',\n",
       " 'fiknllyd',\n",
       " 'fianlluys',\n",
       " 'aianley',\n",
       " 'pfganlly',\n",
       " 'lfianllky',\n",
       " 'fianlccy',\n",
       " 'fiaunllb',\n",
       " 'fidnlli',\n",
       " 'jxanlly',\n",
       " 'yiaylly',\n",
       " 'fiaynllf',\n",
       " 'fjaslly',\n",
       " 'fiayldy',\n",
       " 'fanlljy',\n",
       " 'fuanlgy',\n",
       " 'bianully',\n",
       " 'fifblly',\n",
       " 'fianhplly',\n",
       " 'fianlmla',\n",
       " 'figntly',\n",
       " 'hianlfly',\n",
       " 'fianllwoy',\n",
       " 'fsaqlly',\n",
       " 'fianlkcly',\n",
       " 'feanljly',\n",
       " 'fianlhyf',\n",
       " 'fganylly',\n",
       " 'feianlle',\n",
       " 'fiafflly',\n",
       " 'fianycly',\n",
       " 'fihnblly',\n",
       " 'franjlly',\n",
       " 'gfianlyly',\n",
       " 'fiarwlly',\n",
       " 'jfinnlly',\n",
       " 'fiahfly',\n",
       " 'fiwnlwy',\n",
       " 'fviinlly',\n",
       " 'fcianlky',\n",
       " 'bianljy',\n",
       " 'fyianlnly',\n",
       " 'oianloly',\n",
       " 'fienllpy',\n",
       " 'jfianllo',\n",
       " 'fiaonllby',\n",
       " 'eianllvy',\n",
       " 'fiflnlly',\n",
       " 'fianwlyv',\n",
       " 'fianlmxy',\n",
       " 'zfiahnlly',\n",
       " 'yfoianlly',\n",
       " 'fiwannlly',\n",
       " 'fiaynxly',\n",
       " 'fianillyy',\n",
       " 'frianllyb',\n",
       " 'fianlnely',\n",
       " 'fgxnlly',\n",
       " 'fianvvy',\n",
       " 'fianxlljy',\n",
       " 'fibllly',\n",
       " 'fjianllyc',\n",
       " 'fmawnlly',\n",
       " 'fzamnlly',\n",
       " 'dfianllqy',\n",
       " 'fyihnlly',\n",
       " 'uianlxy',\n",
       " 'hianlily',\n",
       " 'feiavlly',\n",
       " 'fianplpy',\n",
       " 'fianlljwy',\n",
       " 'fionoly',\n",
       " 'gianllx',\n",
       " 'fianylsly',\n",
       " 'fpialnly',\n",
       " 'fitwlly',\n",
       " 'fianluyh',\n",
       " 'fianltlyp',\n",
       " 'fraqlly',\n",
       " 'fdanlle',\n",
       " 'fiavflly',\n",
       " 'fianioly',\n",
       " 'oiajlly',\n",
       " 'jfbanlly',\n",
       " 'fjianlsy',\n",
       " 'jianlly',\n",
       " 'fifanllk',\n",
       " 'fiainlln',\n",
       " 'firadnlly',\n",
       " 'fiaynllyv',\n",
       " 'fzganlly',\n",
       " 'fihanwlly',\n",
       " 'bfianslly',\n",
       " 'fpanllty',\n",
       " 'fiaolnlly',\n",
       " 'gfinnlly',\n",
       " 'ficnllu',\n",
       " 'fianvlls',\n",
       " 'vfianllyj',\n",
       " 'filnllym',\n",
       " 'fianlliyk',\n",
       " 'fianlldy',\n",
       " 'fhnnlly',\n",
       " 'fianllqoy',\n",
       " 'fiinljy',\n",
       " 'oiaplly',\n",
       " 'fxanvly',\n",
       " 'sbianlly',\n",
       " 'fianvzlly',\n",
       " 'fianellyk',\n",
       " 'lfwanlly',\n",
       " 'fiagnlgly',\n",
       " 'fbimanlly',\n",
       " 'flianllyt',\n",
       " 'fyanljy',\n",
       " 'fyiadnlly',\n",
       " 'pfiamlly',\n",
       " 'fiatnldly',\n",
       " 'fianmblly',\n",
       " 'fgiazlly',\n",
       " 'fianrllyo',\n",
       " 'fijaenlly',\n",
       " 'fiajnlzly',\n",
       " 'fivailly',\n",
       " 'mianklly',\n",
       " 'fianlalyc',\n",
       " 'fianlms',\n",
       " 'ifianlty',\n",
       " 'rianllyi',\n",
       " 'fianuey',\n",
       " 'franlliy',\n",
       " 'fijanloly',\n",
       " 'fiaqnlzy',\n",
       " 'fianlefy',\n",
       " 'efianlry',\n",
       " 'fienllvy',\n",
       " 'feanllyj',\n",
       " 'xfjianlly',\n",
       " 'iiawlly',\n",
       " 'zfiarlly',\n",
       " 'fianlltyf',\n",
       " 'hfianllh',\n",
       " 'chianlly',\n",
       " 'fxanlty',\n",
       " 'itianlly',\n",
       " 'fianolyt',\n",
       " 'foanllpy',\n",
       " 'mfhanlly',\n",
       " 'fiantlla',\n",
       " 'fianlgzly',\n",
       " 'zianluy',\n",
       " 'fiabllh',\n",
       " 'fianfty',\n",
       " 'fiaflry',\n",
       " 'ofpianlly',\n",
       " 'fniaznlly',\n",
       " 'miawlly',\n",
       " 'zianllym',\n",
       " 'fennlly',\n",
       " 'fmanvly',\n",
       " 'fiasqlly',\n",
       " 'fganljy',\n",
       " 'ftanllyt',\n",
       " 'pivnlly',\n",
       " 'fianlely',\n",
       " 'niamnlly',\n",
       " 'fiacnllf',\n",
       " 'fianllca',\n",
       " 'fdanlvly',\n",
       " 'femnlly',\n",
       " 'fimnally',\n",
       " 'fianlas',\n",
       " 'fnisanlly',\n",
       " 'fianjlye',\n",
       " 'hnianlly',\n",
       " 'fianple',\n",
       " 'fzanlny',\n",
       " 'fianlloky',\n",
       " 'fixnllyy',\n",
       " 'firylly',\n",
       " 'fqiajnlly',\n",
       " 'fdianllyd',\n",
       " 'fsaqnlly',\n",
       " 'fidanllyi',\n",
       " 'bmanlly',\n",
       " 'fikanely',\n",
       " 'fianldley',\n",
       " 'eiahnlly',\n",
       " 'zfianlls',\n",
       " 'fiaznllb',\n",
       " 'frianlty',\n",
       " 'fianbtly',\n",
       " 'sianlyly',\n",
       " 'nfianjlly',\n",
       " 'fiatlnly',\n",
       " 'oxanlly',\n",
       " 'ftiannlly',\n",
       " 'fionll',\n",
       " 'fixantlly',\n",
       " 'fianpxy',\n",
       " 'pfianblly',\n",
       " 'fibnlfy',\n",
       " 'fianlmlyy',\n",
       " 'fianlclyd',\n",
       " 'fiazlgy',\n",
       " 'fidknlly',\n",
       " 'ficnlty',\n",
       " 'fianollu',\n",
       " 'fianrglly',\n",
       " 'xianllu',\n",
       " 'fiamlley',\n",
       " 'yfianlely',\n",
       " 'fianllyjq',\n",
       " 'tidanlly',\n",
       " 'fhinally',\n",
       " 'zfianlsly',\n",
       " 'nfianmlly',\n",
       " 'flianbly',\n",
       " 'fcanllv',\n",
       " 'fiinll',\n",
       " 'fianlgj',\n",
       " 'fianllyqn',\n",
       " 'fikabnlly',\n",
       " 'efianllyb',\n",
       " 'fiunxly',\n",
       " 'friqnlly',\n",
       " 'fiynll',\n",
       " 'fbanllyw',\n",
       " 'efianlmy',\n",
       " 'fianxry',\n",
       " 'fsianjlly',\n",
       " 'fianllqyn',\n",
       " 'figanzly',\n",
       " 'flanlply',\n",
       " 'jiaqlly',\n",
       " 'fianlloe',\n",
       " 'fiaplloy',\n",
       " 'fwianllyr',\n",
       " 'filnzlly',\n",
       " 'fiafnwlly',\n",
       " 'faatnlly',\n",
       " 'fianllygs',\n",
       " 'finanqly',\n",
       " 'hfianklly',\n",
       " 'fitanllc',\n",
       " 'fianzlly',\n",
       " 'fxianldly',\n",
       " 'fihanlyl',\n",
       " 'fiatllyl',\n",
       " 'mfianllyl',\n",
       " 'fianllydj',\n",
       " 'fiyianlly',\n",
       " 'foamlly',\n",
       " 'fsianllhy',\n",
       " 'fianjllny',\n",
       " 'fifanllay',\n",
       " 'fipslly',\n",
       " 'mfianllyx',\n",
       " 'vfianfly',\n",
       " 'sfianlmly',\n",
       " 'fiaihnlly',\n",
       " 'fianlebly',\n",
       " 'fieanlmly',\n",
       " 'pfiadnlly',\n",
       " 'jfwanlly',\n",
       " 'foanlby',\n",
       " 'efwianlly',\n",
       " 'fhianllw',\n",
       " 'kiaylly',\n",
       " 'fyhianlly',\n",
       " 'fianlwya',\n",
       " 'fianqlgly',\n",
       " 'fnanllf',\n",
       " 'rianllyu',\n",
       " 'fianvlljy',\n",
       " 'kfianlvly',\n",
       " 'fyoianlly',\n",
       " 'fqianlljy',\n",
       " 'rianqly',\n",
       " 'fliznlly',\n",
       " 'fianlkyg',\n",
       " 'fiamllh',\n",
       " 'fiarely',\n",
       " 'fianllyjd',\n",
       " 'fcxanlly',\n",
       " 'fmianllye',\n",
       " 'fianqloy',\n",
       " 'fiansply',\n",
       " 'fiaillys',\n",
       " 'pianqly',\n",
       " 'fhiadlly',\n",
       " 'fetnlly',\n",
       " 'fianlalcy',\n",
       " 'hianclly',\n",
       " 'gfianlhly',\n",
       " 'ayfianlly',\n",
       " 'fixavnlly',\n",
       " 'fianlyxly',\n",
       " 'hfianflly',\n",
       " 'fliatnlly',\n",
       " 'fiuanly',\n",
       " 'aficnlly',\n",
       " 'fianhlyf',\n",
       " 'fiwanllny',\n",
       " 'fiaqnllyc',\n",
       " 'fikntly',\n",
       " 'ffianllya',\n",
       " 'fianay',\n",
       " 'fiazlay',\n",
       " 'fidanllv',\n",
       " 'fkiajlly',\n",
       " 'fhkanlly',\n",
       " 'gfianllw',\n",
       " 'fieanuly',\n",
       " 'fiayolly',\n",
       " 'fianlqyly',\n",
       " 'fjanlsy',\n",
       " 'figanliy',\n",
       " 'fanlrly',\n",
       " 'fpanly',\n",
       " 'ficaqnlly',\n",
       " 'fiaimlly',\n",
       " 'feaxnlly',\n",
       " 'fiarnlmy',\n",
       " 'fliuanlly',\n",
       " 'fiayyly',\n",
       " 'fuianllyo',\n",
       " 'fiarnllyl',\n",
       " 'jufianlly',\n",
       " 'fiaintly',\n",
       " 'fialllyh',\n",
       " 'fianyllyd',\n",
       " 'vfianlljy',\n",
       " 'mfianlfy',\n",
       " 'fianblljy',\n",
       " 'fiwsnlly',\n",
       " 'lfianllyr',\n",
       " 'fiatlsy',\n",
       " 'fiqnlwly',\n",
       " 'tfianlliy',\n",
       " 'fnkianlly',\n",
       " 'fianmllgy',\n",
       " 'afianxlly',\n",
       " 'fijnlby',\n",
       " 'fvianllo',\n",
       " 'fiarnluly',\n",
       " 'fiaannly',\n",
       " 'fianqlyz',\n",
       " 'fzianllyo',\n",
       " 'fitmnlly',\n",
       " 'fiasllyk',\n",
       " 'kfianaly',\n",
       " 'fiznllq',\n",
       " 'fhaqlly',\n",
       " 'mianllyp',\n",
       " 'fiattnlly',\n",
       " 'fieanlhly',\n",
       " 'fiaduly',\n",
       " 'fianolldy',\n",
       " 'cfianjly',\n",
       " 'fiamlldy',\n",
       " 'fiqnllzy',\n",
       " 'fihnrlly',\n",
       " 'tfianlgly',\n",
       " 'fivapnlly',\n",
       " 'aicnlly',\n",
       " 'fvanlnly',\n",
       " 'fianllvh',\n",
       " 'kfianlll',\n",
       " 'fianllvwy',\n",
       " 'fiaznlvy',\n",
       " 'iianlily',\n",
       " 'tianlhly',\n",
       " 'fianlvyc',\n",
       " 'rianllx',\n",
       " 'fialnlyj',\n",
       " 'fianlyjl',\n",
       " 'jianllcy',\n",
       " 'fitnllvy',\n",
       " 'fiqunlly',\n",
       " 'gianllyh',\n",
       " 'fiahnully',\n",
       " 'sfiandlly',\n",
       " 'kianjlly',\n",
       " 'fisnllys',\n",
       " 'fiwanloy',\n",
       " 'fcawnlly',\n",
       " 'fsiyanlly',\n",
       " 'fvjanlly',\n",
       " 'fganully',\n",
       " 'fianbry',\n",
       " 'fianlfwy',\n",
       " 'fiveanlly',\n",
       " 'iannly',\n",
       " 'fiattlly',\n",
       " 'uianllym',\n",
       " 'qianlpy',\n",
       " 'fianlla',\n",
       " 'fianxay',\n",
       " 'fianulwly',\n",
       " 'miantly',\n",
       " 'fzianlaly',\n",
       " 'fuiknlly',\n",
       " 'aianllj',\n",
       " 'ftionlly',\n",
       " 'fiqanllyk',\n",
       " 'fikrlly',\n",
       " 'hfiknlly',\n",
       " 'fiagljy',\n",
       " 'zianllr',\n",
       " 'fxanllyh',\n",
       " 'ocianlly',\n",
       " 'hfianhlly',\n",
       " 'fcabnlly',\n",
       " 'fjirnlly',\n",
       " 'fiaulll',\n",
       " 'jfhanlly',\n",
       " 'pianllyt',\n",
       " 'jianuly',\n",
       " 'flianllcy',\n",
       " 'qpianlly',\n",
       " 'fianllnm',\n",
       " 'fiqlly',\n",
       " 'fiaellyz',\n",
       " 'sibnlly',\n",
       " 'fuianllu',\n",
       " 'fiaznllty',\n",
       " 'biantly',\n",
       " 'fiayily',\n",
       " 'avanlly',\n",
       " 'dfianllyi',\n",
       " 'fiafllzy',\n",
       " 'fivnlmly',\n",
       " 'fixannly',\n",
       " 'xianllyw',\n",
       " 'dfianwlly',\n",
       " 'fqiwanlly',\n",
       " 'ffinlly',\n",
       " 'fianlels',\n",
       " 'fianllua',\n",
       " 'fiinglly',\n",
       " 'fqanllyi',\n",
       " 'faioanlly',\n",
       " 'gfiallly',\n",
       " 'btanlly',\n",
       " 'fjianllf',\n",
       " 'hivanlly',\n",
       " 'oizanlly',\n",
       " 'fqanily',\n",
       " 'fiaklbly',\n",
       " 'fiadhly',\n",
       " 'fiaknlpy',\n",
       " 'jfiacnlly',\n",
       " 'fiaenyly',\n",
       " 'fuanllsy',\n",
       " 'fianlrlq',\n",
       " 'firnllzy',\n",
       " 'fianlltyg',\n",
       " 'ficancly',\n",
       " 'fiasnllyr',\n",
       " 'fianjllyi',\n",
       " 'fiapllv',\n",
       " 'fianpllz',\n",
       " 'fianltlyt',\n",
       " 'siaclly',\n",
       " 'fiayllyc',\n",
       " 'fizwanlly',\n",
       " 'fhanllay',\n",
       " 'fsanjly',\n",
       " 'fianliley',\n",
       " 'zdanlly',\n",
       " 'fdanlzly',\n",
       " 'fisnelly',\n",
       " 'iiaklly',\n",
       " 'fihoanlly',\n",
       " 'fiagnolly',\n",
       " 'iianally',\n",
       " 'qianllyy',\n",
       " 'kfianhlly',\n",
       " 'fiannllpy',\n",
       " 'diadlly',\n",
       " 'fbianllr',\n",
       " 'fidanljly',\n",
       " 'ffnianlly',\n",
       " 'fiwnllvy',\n",
       " 'ftajlly',\n",
       " 'rianlvly',\n",
       " 'fikanlcly',\n",
       " 'zieanlly',\n",
       " 'fihanllq',\n",
       " 'hiaqnlly',\n",
       " 'fihnllq',\n",
       " 'ffianllyu',\n",
       " 'fiaswlly',\n",
       " 'fifnlls',\n",
       " 'fianlgyly',\n",
       " 'fwiansly',\n",
       " 'fianflj',\n",
       " 'fgianllsy',\n",
       " 'fianmlluy',\n",
       " 'fmivanlly',\n",
       " 'wfiamlly',\n",
       " 'bfiawnlly',\n",
       " 'fitanhlly',\n",
       " 'fianyljly',\n",
       " 'fimanlcy',\n",
       " 'oiaenlly',\n",
       " 'fiqganlly',\n",
       " 'ffianlgly',\n",
       " 'fzanllt',\n",
       " 'fkivnlly',\n",
       " 'fwanllyw',\n",
       " 'fmankly',\n",
       " 'fiaonlzy',\n",
       " 'rjianlly',\n",
       " 'fvianslly',\n",
       " 'fianlluv',\n",
       " 'afianlcly',\n",
       " 'fiangelly',\n",
       " 'fiainllym',\n",
       " 'fianllxyz',\n",
       " 'fianllyis',\n",
       " 'fiaenllqy',\n",
       " 'lfuianlly',\n",
       " 'flitanlly',\n",
       " 'ffiapnlly',\n",
       " 'fiagloly',\n",
       " 'fianellyv',\n",
       " 'firanjly',\n",
       " 'fiinflly',\n",
       " 'fianlwyt',\n",
       " 'fiapnllay',\n",
       " 'fiagnmly',\n",
       " 'fianvully',\n",
       " 'frianlzy',\n",
       " 'mfianlnly',\n",
       " 'fiaillc',\n",
       " 'fsanhlly',\n",
       " 'fiunlyy',\n",
       " 'eianllyg',\n",
       " 'xiyanlly',\n",
       " 'fiarnslly',\n",
       " 'yivanlly',\n",
       " 'dfiknlly',\n",
       " 'fianzlfly',\n",
       " 'fzgnlly',\n",
       " 'fianity',\n",
       " 'xfpanlly',\n",
       " 'kfiarnlly',\n",
       " 'fianlpsy',\n",
       " 'fjianly',\n",
       " 'fswianlly',\n",
       " 'fianloy',\n",
       " 'ffianllyg',\n",
       " 'fiaslgy',\n",
       " 'fignllyo',\n",
       " 'fbanwlly',\n",
       " 'fimanliy',\n",
       " 'fianzlwly',\n",
       " 'fiacnolly',\n",
       " 'jnanlly',\n",
       " 'fianpllsy',\n",
       " 'fizajlly',\n",
       " 'fisatnlly',\n",
       " 'dfianllzy',\n",
       " 'xibnlly',\n",
       " 'ffibanlly',\n",
       " 'pnfianlly',\n",
       " 'fzanrlly',\n",
       " 'fhirnlly',\n",
       " 'fianlnlsy',\n",
       " 'cianwly',\n",
       " 'fianlau',\n",
       " 'fiajllny',\n",
       " 'fianllyzt',\n",
       " 'xficnlly',\n",
       " 'gfivanlly',\n",
       " 'fianlllzy',\n",
       " 'fvianjly',\n",
       " 'rmanlly',\n",
       " 'fiaelvy',\n",
       " 'fnanley',\n",
       " 'fibnllny',\n",
       " 'fyanlcy',\n",
       " 'fxanlld',\n",
       " 'fianllyda',\n",
       " 'fpannly',\n",
       " 'fiaivly',\n",
       " 'fzianllyi',\n",
       " 'fvpnlly',\n",
       " 'fianjgy',\n",
       " 'fianmlyg',\n",
       " 'fianolty',\n",
       " 'wianljy',\n",
       " 'fianalyu',\n",
       " 'dianllwy',\n",
       " 'afianllby',\n",
       " 'ftanllyc',\n",
       " 'xfianllyp',\n",
       " 'flanlfly',\n",
       " 'ninanlly',\n",
       " 'fiaqlpy',\n",
       " 'qfiinlly',\n",
       " 'fdanbly',\n",
       " 'zfirnlly',\n",
       " 'tfianily',\n",
       " 'qianll',\n",
       " 'fianzllcy',\n",
       " 'fiuanllhy',\n",
       " 'fianlnz',\n",
       " 'fieylly',\n",
       " 'rianllty',\n",
       " 'pfifnlly',\n",
       " 'ofianllyj',\n",
       " 'fxinnlly',\n",
       " 'fiailaly',\n",
       " 'fiannljy',\n",
       " 'ufianely',\n",
       " 'fzanjly',\n",
       " 'fainllz',\n",
       " 'cbanlly',\n",
       " 'fcenlly',\n",
       " 'fiallluy',\n",
       " 'pwanlly',\n",
       " 'fsivanlly',\n",
       " 'fctanlly',\n",
       " 'fjanlry',\n",
       " 'ifianllys',\n",
       " 'wfqianlly',\n",
       " 'zkanlly',\n",
       " 'fimtlly',\n",
       " 'fihnll',\n",
       " 'fiqnlsly',\n",
       " 'fiqanllc',\n",
       " 'fianlaljy',\n",
       " 'fialynlly',\n",
       " 'fiaanely',\n",
       " 'fiaqnlqly',\n",
       " 'vfiansly',\n",
       " 'fiqanllyc',\n",
       " 'hfianlzy',\n",
       " 'fianflloy',\n",
       " 'fianplply',\n",
       " 'fniandlly',\n",
       " 'tialnlly',\n",
       " 'fiahglly',\n",
       " 'ricanlly',\n",
       " 'fialnllgy',\n",
       " 'oianlyy',\n",
       " 'fianglrly',\n",
       " 'fwanrlly',\n",
       " 'fiahxlly',\n",
       " 'fioangly',\n",
       " 'vfiaelly',\n",
       " 'fbanllky',\n",
       " 'fianlwlxy',\n",
       " 'fiuanlcly',\n",
       " 'fqanllp',\n",
       " 'fianlldr',\n",
       " 'fiaplhy',\n",
       " 'franlby',\n",
       " 'fiqnlla',\n",
       " 'fineanlly',\n",
       " 'fixanllyl',\n",
       " 'fianlmlj',\n",
       " 'fnianlle',\n",
       " 'fimanrly',\n",
       " 'sianqlly',\n",
       " 'fianuld',\n",
       " 'fianliyl',\n",
       " 'fiaonglly',\n",
       " 'ffianllf',\n",
       " 'fianlkd',\n",
       " 'fhanll',\n",
       " 'qnanlly',\n",
       " 'finallty',\n",
       " 'kfiqanlly',\n",
       " 'fixally',\n",
       " 'fiawnljy',\n",
       " 'fiaclrly',\n",
       " 'fiaxlmly',\n",
       " 'fialnlyly',\n",
       " 'fianeld',\n",
       " 'yfianllyg',\n",
       " 'fianllyaj',\n",
       " 'fianably',\n",
       " 'fianleay',\n",
       " 'fiiaznlly',\n",
       " 'fijnoly',\n",
       " 'fnanlzly',\n",
       " 'ftanlls',\n",
       " 'fijahlly',\n",
       " 'fitnllys',\n",
       " 'fianllogy',\n",
       " 'fiinxlly',\n",
       " 'vfianzly',\n",
       " 'fwinanlly',\n",
       " 'fikanlvly',\n",
       " 'flanxly',\n",
       " 'fiaulnly',\n",
       " 'fianllgyi',\n",
       " 'fioanllr',\n",
       " 'fztianlly',\n",
       " 'fieanlgy',\n",
       " 'fiandlfly',\n",
       " 'fiwnllyc',\n",
       " 'fianlik',\n",
       " 'fiablkly',\n",
       " 'flpanlly',\n",
       " 'zfhanlly',\n",
       " 'fipanlwy',\n",
       " 'fhianxlly',\n",
       " 'fiavllky',\n",
       " 'fianvllm',\n",
       " 'fqianlbly',\n",
       " 'fiaonlyy',\n",
       " 'jfiantlly',\n",
       " 'fxipnlly',\n",
       " 'fiabnljly',\n",
       " 'fianbluly',\n",
       " 'fecanlly',\n",
       " 'fhiyanlly',\n",
       " 'fianlhyq',\n",
       " 'fianeoy',\n",
       " 'nianlny',\n",
       " 'fiadllw',\n",
       " 'qiaanlly',\n",
       " 'fiamnllj',\n",
       " 'fsanely',\n",
       " 'fsaknlly',\n",
       " 'fzianuly',\n",
       " 'liansly',\n",
       " 'fianlelys',\n",
       " 'fdianlfly',\n",
       " 'ifimanlly',\n",
       " 'flnally',\n",
       " 'fyifanlly',\n",
       " 'ntanlly',\n",
       " 'fganlely',\n",
       " 'fiaooly',\n",
       " 'efianelly',\n",
       " 'fiasnwly',\n",
       " 'fianlgry',\n",
       " 'fxanllyc',\n",
       " 'fijnllyn',\n",
       " 'fiaknllyo',\n",
       " 'nianlzy',\n",
       " 'rvianlly',\n",
       " 'ifianlzy',\n",
       " 'vfiaslly',\n",
       " 'fianlzply',\n",
       " 'oianolly',\n",
       " 'fiunlvy',\n",
       " 'fijanllt',\n",
       " 'fianlilz',\n",
       " 'fianpllty',\n",
       " 'fifanlsly',\n",
       " 'fiaytlly',\n",
       " 'pianxlly',\n",
       " 'fignnly',\n",
       " 'fianlylsy',\n",
       " 'fjoianlly',\n",
       " 'fzianglly',\n",
       " 'bianplly',\n",
       " 'fianzlr',\n",
       " 'fxiianlly',\n",
       " 'fiavnllyl',\n",
       " 'qmianlly',\n",
       " 'fijnlily',\n",
       " 'fianejly',\n",
       " 'fwianllyb',\n",
       " 'fganlldy',\n",
       " 'fiannlln',\n",
       " 'pfisanlly',\n",
       " 'fianpllg',\n",
       " 'fhiaslly',\n",
       " 'fzicnlly',\n",
       " 'fianlily',\n",
       " 'fsanhly',\n",
       " 'fiavllyf',\n",
       " ...}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two edit distances from input word\n",
    "edits2(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits1(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fianlxlyz',\n",
       " 'fiasnrly',\n",
       " 'fnanllyk',\n",
       " 'fiadnlay',\n",
       " 'fianltlyq',\n",
       " 'iiafnlly',\n",
       " 'fiaznlky',\n",
       " 'fianlndy',\n",
       " 'fztnlly',\n",
       " 'liadlly',\n",
       " 'fzianllg',\n",
       " 'fgianllvy',\n",
       " 'fianjlkly',\n",
       " 'fianqllyn',\n",
       " 'fkbanlly',\n",
       " 'fiafllo',\n",
       " 'bfianllo',\n",
       " 'fpainlly',\n",
       " 'fiunllt',\n",
       " 'tfiaully',\n",
       " 'fyaslly',\n",
       " 'fienglly',\n",
       " 'rianllr',\n",
       " 'riandly',\n",
       " 'fmianllyh',\n",
       " 'fiagllny',\n",
       " 'kfiaknlly',\n",
       " 'fianyley',\n",
       " 'nianllyr',\n",
       " 'cfianllyk',\n",
       " 'fianlile',\n",
       " 'rianllz',\n",
       " 'fianlloys',\n",
       " 'yianlpy',\n",
       " 'fiqnjlly',\n",
       " 'fiqnllay',\n",
       " 'xfiaxnlly',\n",
       " 'fiqnaly',\n",
       " 'ziaglly',\n",
       " 'uianrly',\n",
       " 'fiaialy',\n",
       " 'fzaglly',\n",
       " 'fipnllyd',\n",
       " 'fcianlqy',\n",
       " 'fikwanlly',\n",
       " 'cfianlcy',\n",
       " 'fihnllvy',\n",
       " 'fsianljly',\n",
       " 'fiagnoly',\n",
       " 'fiavlzly',\n",
       " 'kffanlly',\n",
       " 'fianulf',\n",
       " 'fianloby',\n",
       " 'faanlyly',\n",
       " 'fianbllyl',\n",
       " 'fiagldy',\n",
       " 'fzianllp',\n",
       " 'fiagllay',\n",
       " 'fpaqlly',\n",
       " 'wfianlldy',\n",
       " 'fgianhly',\n",
       " 'fianlleyz',\n",
       " 'fiakllyu',\n",
       " 'fliawlly',\n",
       " 'fihanally',\n",
       " 'fdanlny',\n",
       " 'fignkly',\n",
       " 'fiahrlly',\n",
       " 'frianlely',\n",
       " 'fienluy',\n",
       " 'fianllyjg',\n",
       " 'fianpllyp',\n",
       " 'fianllqyf',\n",
       " 'fiaydnlly',\n",
       " 'fiarilly',\n",
       " 'finnlvly',\n",
       " 'fqionlly',\n",
       " 'fiaxlry',\n",
       " 'fqanhlly',\n",
       " 'fiamllq',\n",
       " 'jfiandly',\n",
       " 'fhiandlly',\n",
       " 'fiuanblly',\n",
       " 'rfianlty',\n",
       " 'limnlly',\n",
       " 'fijanllyn',\n",
       " 'fbeanlly',\n",
       " 'ftianllvy',\n",
       " 'fmianlpy',\n",
       " 'fifnllb',\n",
       " 'fanlzy',\n",
       " 'fiazhnlly',\n",
       " 'iianllu',\n",
       " 'feanvly',\n",
       " 'sfianzly',\n",
       " 'fbianllo',\n",
       " 'fiagkly',\n",
       " 'efiznlly',\n",
       " 'fivanply',\n",
       " 'fikanvly',\n",
       " 'viaclly',\n",
       " 'fianlsyo',\n",
       " 'fiazllu',\n",
       " 'fiazynlly',\n",
       " 'fianlkf',\n",
       " 'fkanlfy',\n",
       " 'gianllyz',\n",
       " 'fiaqwly',\n",
       " 'hfwianlly',\n",
       " 'fciaanlly',\n",
       " 'fiainllly',\n",
       " 'fipanelly',\n",
       " 'zfianqly',\n",
       " 'ppanlly',\n",
       " 'fmvianlly',\n",
       " 'xiaanlly',\n",
       " 'zffianlly',\n",
       " 'xfitnlly',\n",
       " 'iefianlly',\n",
       " 'fqianally',\n",
       " 'fiancdy',\n",
       " 'bfioanlly',\n",
       " 'fiaemlly',\n",
       " 'fianllxuy',\n",
       " 'fiahnsly',\n",
       " 'fjianllj',\n",
       " 'ffiarnlly',\n",
       " 'fjiarlly',\n",
       " 'fianllnuy',\n",
       " 'fianlnfy',\n",
       " 'eianlhly',\n",
       " 'fisanrlly',\n",
       " 'ifianllyd',\n",
       " 'flianll',\n",
       " 'fitnllay',\n",
       " 'fiacllny',\n",
       " 'fiytanlly',\n",
       " 'fijanllf',\n",
       " 'rfiamnlly',\n",
       " 'fdanllyf',\n",
       " 'fiagdnlly',\n",
       " 'fianqlay',\n",
       " 'figarnlly',\n",
       " 'fsiangly',\n",
       " 'fianallby',\n",
       " 'ffoanlly',\n",
       " 'finanllyu',\n",
       " 'fxanlls',\n",
       " 'mienlly',\n",
       " 'iianllyb',\n",
       " 'fianalk',\n",
       " 'foiaunlly',\n",
       " 'fianlylyx',\n",
       " 'fipnllya',\n",
       " 'fmanllfy',\n",
       " 'ojfianlly',\n",
       " 'fiancgy',\n",
       " 'nianxly',\n",
       " 'aianclly',\n",
       " 'fianljw',\n",
       " 'fiatnllyr',\n",
       " 'fianldty',\n",
       " 'fianlkfy',\n",
       " 'ianllx',\n",
       " 'fikxnlly',\n",
       " 'fiaylvy',\n",
       " 'xiknlly',\n",
       " 'fbinally',\n",
       " 'sianwly',\n",
       " 'frianllb',\n",
       " 'ftiantly',\n",
       " 'lfranlly',\n",
       " 'feianmly',\n",
       " 'fdianllyo',\n",
       " 'fiaglnly',\n",
       " 'fitanllmy',\n",
       " 'fsiaglly',\n",
       " 'fkapnlly',\n",
       " 'fianlwyk',\n",
       " 'gianlsy',\n",
       " 'fietanlly',\n",
       " 'fsanllu',\n",
       " 'fianlklyd',\n",
       " 'lbanlly',\n",
       " 'yfbanlly',\n",
       " 'dfiatlly',\n",
       " 'fkatnlly',\n",
       " 'ksfianlly',\n",
       " 'fiaallj',\n",
       " 'ficnlgy',\n",
       " 'fxianuly',\n",
       " 'fiaqnylly',\n",
       " 'fisahnlly',\n",
       " 'fianlxy',\n",
       " 'fiatnlhly',\n",
       " 'sianzly',\n",
       " 'fianlloy',\n",
       " 'fianswly',\n",
       " 'fihglly',\n",
       " 'fiaglljy',\n",
       " 'fviazlly',\n",
       " 'fiaznllyt',\n",
       " 'fianbzy',\n",
       " 'faianltly',\n",
       " 'eiynlly',\n",
       " 'fivanslly',\n",
       " 'fiarlls',\n",
       " 'eianllyu',\n",
       " 'fiatnlzly',\n",
       " 'pianrly',\n",
       " 'fiaalcy',\n",
       " 'finanally',\n",
       " 'fiainlloy',\n",
       " 'vially',\n",
       " 'fianlklyo',\n",
       " 'fjanllo',\n",
       " 'fianllgyv',\n",
       " 'xfiajnlly',\n",
       " 'fpanllny',\n",
       " 'fliazlly',\n",
       " 'tfianllny',\n",
       " 'fiknllyd',\n",
       " 'fianlluys',\n",
       " 'aianley',\n",
       " 'pfganlly',\n",
       " 'lfianllky',\n",
       " 'fianlccy',\n",
       " 'fiaunllb',\n",
       " 'fidnlli',\n",
       " 'jxanlly',\n",
       " 'yiaylly',\n",
       " 'fiaynllf',\n",
       " 'fjaslly',\n",
       " 'fiayldy',\n",
       " 'fanlljy',\n",
       " 'fuanlgy',\n",
       " 'bianully',\n",
       " 'fifblly',\n",
       " 'fianhplly',\n",
       " 'fianlmla',\n",
       " 'figntly',\n",
       " 'hianlfly',\n",
       " 'fianllwoy',\n",
       " 'fsaqlly',\n",
       " 'fianlkcly',\n",
       " 'feanljly',\n",
       " 'fianlhyf',\n",
       " 'fganylly',\n",
       " 'feianlle',\n",
       " 'fiafflly',\n",
       " 'fianycly',\n",
       " 'fihnblly',\n",
       " 'franjlly',\n",
       " 'gfianlyly',\n",
       " 'fiarwlly',\n",
       " 'jfinnlly',\n",
       " 'fiahfly',\n",
       " 'fiwnlwy',\n",
       " 'fviinlly',\n",
       " 'fcianlky',\n",
       " 'bianljy',\n",
       " 'fyianlnly',\n",
       " 'oianloly',\n",
       " 'fienllpy',\n",
       " 'jfianllo',\n",
       " 'fiaonllby',\n",
       " 'eianllvy',\n",
       " 'fiflnlly',\n",
       " 'fianwlyv',\n",
       " 'fianlmxy',\n",
       " 'zfiahnlly',\n",
       " 'yfoianlly',\n",
       " 'fiwannlly',\n",
       " 'fiaynxly',\n",
       " 'fianillyy',\n",
       " 'frianllyb',\n",
       " 'fianlnely',\n",
       " 'fgxnlly',\n",
       " 'fianvvy',\n",
       " 'fianxlljy',\n",
       " 'fibllly',\n",
       " 'fjianllyc',\n",
       " 'fmawnlly',\n",
       " 'fzamnlly',\n",
       " 'dfianllqy',\n",
       " 'fyihnlly',\n",
       " 'uianlxy',\n",
       " 'hianlily',\n",
       " 'feiavlly',\n",
       " 'fianplpy',\n",
       " 'fianlljwy',\n",
       " 'fionoly',\n",
       " 'gianllx',\n",
       " 'fianylsly',\n",
       " 'fpialnly',\n",
       " 'fitwlly',\n",
       " 'fianluyh',\n",
       " 'fianltlyp',\n",
       " 'fraqlly',\n",
       " 'fdanlle',\n",
       " 'fiavflly',\n",
       " 'fianioly',\n",
       " 'oiajlly',\n",
       " 'jfbanlly',\n",
       " 'fjianlsy',\n",
       " 'jianlly',\n",
       " 'fifanllk',\n",
       " 'fiainlln',\n",
       " 'firadnlly',\n",
       " 'fiaynllyv',\n",
       " 'fzganlly',\n",
       " 'fihanwlly',\n",
       " 'bfianslly',\n",
       " 'fpanllty',\n",
       " 'fiaolnlly',\n",
       " 'gfinnlly',\n",
       " 'ficnllu',\n",
       " 'fianvlls',\n",
       " 'vfianllyj',\n",
       " 'filnllym',\n",
       " 'fianlliyk',\n",
       " 'fianlldy',\n",
       " 'fhnnlly',\n",
       " 'fianllqoy',\n",
       " 'fiinljy',\n",
       " 'oiaplly',\n",
       " 'fxanvly',\n",
       " 'sbianlly',\n",
       " 'fianvzlly',\n",
       " 'fianellyk',\n",
       " 'lfwanlly',\n",
       " 'fiagnlgly',\n",
       " 'fbimanlly',\n",
       " 'flianllyt',\n",
       " 'fyanljy',\n",
       " 'fyiadnlly',\n",
       " 'pfiamlly',\n",
       " 'fiatnldly',\n",
       " 'fianmblly',\n",
       " 'fgiazlly',\n",
       " 'fianrllyo',\n",
       " 'fijaenlly',\n",
       " 'fiajnlzly',\n",
       " 'fivailly',\n",
       " 'mianklly',\n",
       " 'fianlalyc',\n",
       " 'fianlms',\n",
       " 'ifianlty',\n",
       " 'rianllyi',\n",
       " 'fianuey',\n",
       " 'franlliy',\n",
       " 'fijanloly',\n",
       " 'fiaqnlzy',\n",
       " 'fianlefy',\n",
       " 'efianlry',\n",
       " 'fienllvy',\n",
       " 'feanllyj',\n",
       " 'xfjianlly',\n",
       " 'iiawlly',\n",
       " 'zfiarlly',\n",
       " 'fianlltyf',\n",
       " 'hfianllh',\n",
       " 'chianlly',\n",
       " 'fxanlty',\n",
       " 'itianlly',\n",
       " 'fianolyt',\n",
       " 'foanllpy',\n",
       " 'mfhanlly',\n",
       " 'fiantlla',\n",
       " 'fianlgzly',\n",
       " 'zianluy',\n",
       " 'fiabllh',\n",
       " 'fianfty',\n",
       " 'fiaflry',\n",
       " 'ofpianlly',\n",
       " 'fniaznlly',\n",
       " 'miawlly',\n",
       " 'zianllym',\n",
       " 'fennlly',\n",
       " 'fmanvly',\n",
       " 'fiasqlly',\n",
       " 'fganljy',\n",
       " 'ftanllyt',\n",
       " 'pivnlly',\n",
       " 'fianlely',\n",
       " 'niamnlly',\n",
       " 'fiacnllf',\n",
       " 'fianllca',\n",
       " 'fdanlvly',\n",
       " 'femnlly',\n",
       " 'fimnally',\n",
       " 'fianlas',\n",
       " 'fnisanlly',\n",
       " 'fianjlye',\n",
       " 'hnianlly',\n",
       " 'fianple',\n",
       " 'fzanlny',\n",
       " 'fianlloky',\n",
       " 'fixnllyy',\n",
       " 'firylly',\n",
       " 'fqiajnlly',\n",
       " 'fdianllyd',\n",
       " 'fsaqnlly',\n",
       " 'fidanllyi',\n",
       " 'bmanlly',\n",
       " 'fikanely',\n",
       " 'fianldley',\n",
       " 'eiahnlly',\n",
       " 'zfianlls',\n",
       " 'fiaznllb',\n",
       " 'frianlty',\n",
       " 'fianbtly',\n",
       " 'sianlyly',\n",
       " 'nfianjlly',\n",
       " 'fiatlnly',\n",
       " 'oxanlly',\n",
       " 'ftiannlly',\n",
       " 'fionll',\n",
       " 'fixantlly',\n",
       " 'fianpxy',\n",
       " 'pfianblly',\n",
       " 'fibnlfy',\n",
       " 'fianlmlyy',\n",
       " 'fianlclyd',\n",
       " 'fiazlgy',\n",
       " 'fidknlly',\n",
       " 'ficnlty',\n",
       " 'fianollu',\n",
       " 'fianrglly',\n",
       " 'xianllu',\n",
       " 'fiamlley',\n",
       " 'yfianlely',\n",
       " 'fianllyjq',\n",
       " 'tidanlly',\n",
       " 'fhinally',\n",
       " 'zfianlsly',\n",
       " 'nfianmlly',\n",
       " 'flianbly',\n",
       " 'fcanllv',\n",
       " 'fiinll',\n",
       " 'fianlgj',\n",
       " 'fianllyqn',\n",
       " 'fikabnlly',\n",
       " 'efianllyb',\n",
       " 'fiunxly',\n",
       " 'friqnlly',\n",
       " 'fiynll',\n",
       " 'fbanllyw',\n",
       " 'efianlmy',\n",
       " 'fianxry',\n",
       " 'fsianjlly',\n",
       " 'fianllqyn',\n",
       " 'figanzly',\n",
       " 'flanlply',\n",
       " 'jiaqlly',\n",
       " 'fianlloe',\n",
       " 'fiaplloy',\n",
       " 'fwianllyr',\n",
       " 'filnzlly',\n",
       " 'fiafnwlly',\n",
       " 'faatnlly',\n",
       " 'fianllygs',\n",
       " 'finanqly',\n",
       " 'hfianklly',\n",
       " 'fitanllc',\n",
       " 'fianzlly',\n",
       " 'fxianldly',\n",
       " 'fihanlyl',\n",
       " 'fiatllyl',\n",
       " 'mfianllyl',\n",
       " 'fianllydj',\n",
       " 'fiyianlly',\n",
       " 'foamlly',\n",
       " 'fsianllhy',\n",
       " 'fianjllny',\n",
       " 'fifanllay',\n",
       " 'fipslly',\n",
       " 'mfianllyx',\n",
       " 'vfianfly',\n",
       " 'sfianlmly',\n",
       " 'fiaihnlly',\n",
       " 'fianlebly',\n",
       " 'fieanlmly',\n",
       " 'pfiadnlly',\n",
       " 'jfwanlly',\n",
       " 'foanlby',\n",
       " 'efwianlly',\n",
       " 'fhianllw',\n",
       " 'kiaylly',\n",
       " 'fyhianlly',\n",
       " 'fianlwya',\n",
       " 'fianqlgly',\n",
       " 'fnanllf',\n",
       " 'rianllyu',\n",
       " 'fianvlljy',\n",
       " 'kfianlvly',\n",
       " 'fyoianlly',\n",
       " 'fqianlljy',\n",
       " 'rianqly',\n",
       " 'fliznlly',\n",
       " 'fianlkyg',\n",
       " 'fiamllh',\n",
       " 'fiarely',\n",
       " 'fianllyjd',\n",
       " 'fcxanlly',\n",
       " 'fmianllye',\n",
       " 'fianqloy',\n",
       " 'fiansply',\n",
       " 'fiaillys',\n",
       " 'pianqly',\n",
       " 'fhiadlly',\n",
       " 'fetnlly',\n",
       " 'fianlalcy',\n",
       " 'hianclly',\n",
       " 'gfianlhly',\n",
       " 'ayfianlly',\n",
       " 'fixavnlly',\n",
       " 'fianlyxly',\n",
       " 'hfianflly',\n",
       " 'fliatnlly',\n",
       " 'fiuanly',\n",
       " 'aficnlly',\n",
       " 'fianhlyf',\n",
       " 'fiwanllny',\n",
       " 'fiaqnllyc',\n",
       " 'fikntly',\n",
       " 'ffianllya',\n",
       " 'fianay',\n",
       " 'fiazlay',\n",
       " 'fidanllv',\n",
       " 'fkiajlly',\n",
       " 'fhkanlly',\n",
       " 'gfianllw',\n",
       " 'fieanuly',\n",
       " 'fiayolly',\n",
       " 'fianlqyly',\n",
       " 'fjanlsy',\n",
       " 'figanliy',\n",
       " 'fanlrly',\n",
       " 'fpanly',\n",
       " 'ficaqnlly',\n",
       " 'fiaimlly',\n",
       " 'feaxnlly',\n",
       " 'fiarnlmy',\n",
       " 'fliuanlly',\n",
       " 'fiayyly',\n",
       " 'fuianllyo',\n",
       " 'fiarnllyl',\n",
       " 'jufianlly',\n",
       " 'fiaintly',\n",
       " 'fialllyh',\n",
       " 'fianyllyd',\n",
       " 'vfianlljy',\n",
       " 'mfianlfy',\n",
       " 'fianblljy',\n",
       " 'fiwsnlly',\n",
       " 'lfianllyr',\n",
       " 'fiatlsy',\n",
       " 'fiqnlwly',\n",
       " 'tfianlliy',\n",
       " 'fnkianlly',\n",
       " 'fianmllgy',\n",
       " 'afianxlly',\n",
       " 'fijnlby',\n",
       " 'fvianllo',\n",
       " 'fiarnluly',\n",
       " 'fiaannly',\n",
       " 'fianqlyz',\n",
       " 'fzianllyo',\n",
       " 'fitmnlly',\n",
       " 'fiasllyk',\n",
       " 'kfianaly',\n",
       " 'fiznllq',\n",
       " 'fhaqlly',\n",
       " 'mianllyp',\n",
       " 'fiattnlly',\n",
       " 'fieanlhly',\n",
       " 'fiaduly',\n",
       " 'fianolldy',\n",
       " 'cfianjly',\n",
       " 'fiamlldy',\n",
       " 'fiqnllzy',\n",
       " 'fihnrlly',\n",
       " 'tfianlgly',\n",
       " 'fivapnlly',\n",
       " 'aicnlly',\n",
       " 'fvanlnly',\n",
       " 'fianllvh',\n",
       " 'kfianlll',\n",
       " 'fianllvwy',\n",
       " 'fiaznlvy',\n",
       " 'iianlily',\n",
       " 'tianlhly',\n",
       " 'fianlvyc',\n",
       " 'rianllx',\n",
       " 'fialnlyj',\n",
       " 'fianlyjl',\n",
       " 'jianllcy',\n",
       " 'fitnllvy',\n",
       " 'fiqunlly',\n",
       " 'gianllyh',\n",
       " 'fiahnully',\n",
       " 'sfiandlly',\n",
       " 'kianjlly',\n",
       " 'fisnllys',\n",
       " 'fiwanloy',\n",
       " 'fcawnlly',\n",
       " 'fsiyanlly',\n",
       " 'fvjanlly',\n",
       " 'fganully',\n",
       " 'fianbry',\n",
       " 'fianlfwy',\n",
       " 'fiveanlly',\n",
       " 'iannly',\n",
       " 'fiattlly',\n",
       " 'uianllym',\n",
       " 'qianlpy',\n",
       " 'fianlla',\n",
       " 'fianxay',\n",
       " 'fianulwly',\n",
       " 'miantly',\n",
       " 'fzianlaly',\n",
       " 'fuiknlly',\n",
       " 'aianllj',\n",
       " 'ftionlly',\n",
       " 'fiqanllyk',\n",
       " 'fikrlly',\n",
       " 'hfiknlly',\n",
       " 'fiagljy',\n",
       " 'zianllr',\n",
       " 'fxanllyh',\n",
       " 'ocianlly',\n",
       " 'hfianhlly',\n",
       " 'fcabnlly',\n",
       " 'fjirnlly',\n",
       " 'fiaulll',\n",
       " 'jfhanlly',\n",
       " 'pianllyt',\n",
       " 'jianuly',\n",
       " 'flianllcy',\n",
       " 'qpianlly',\n",
       " 'fianllnm',\n",
       " 'fiqlly',\n",
       " 'fiaellyz',\n",
       " 'sibnlly',\n",
       " 'fuianllu',\n",
       " 'fiaznllty',\n",
       " 'biantly',\n",
       " 'fiayily',\n",
       " 'avanlly',\n",
       " 'dfianllyi',\n",
       " 'fiafllzy',\n",
       " 'fivnlmly',\n",
       " 'fixannly',\n",
       " 'xianllyw',\n",
       " 'dfianwlly',\n",
       " 'fqiwanlly',\n",
       " 'ffinlly',\n",
       " 'fianlels',\n",
       " 'fianllua',\n",
       " 'fiinglly',\n",
       " 'fqanllyi',\n",
       " 'faioanlly',\n",
       " 'gfiallly',\n",
       " 'btanlly',\n",
       " 'fjianllf',\n",
       " 'hivanlly',\n",
       " 'oizanlly',\n",
       " 'fqanily',\n",
       " 'fiaklbly',\n",
       " 'fiadhly',\n",
       " 'fiaknlpy',\n",
       " 'jfiacnlly',\n",
       " 'fiaenyly',\n",
       " 'fuanllsy',\n",
       " 'fianlrlq',\n",
       " 'firnllzy',\n",
       " 'fianlltyg',\n",
       " 'ficancly',\n",
       " 'fiasnllyr',\n",
       " 'fianjllyi',\n",
       " 'fiapllv',\n",
       " 'fianpllz',\n",
       " 'fianltlyt',\n",
       " 'siaclly',\n",
       " 'fiayllyc',\n",
       " 'fizwanlly',\n",
       " 'fhanllay',\n",
       " 'fsanjly',\n",
       " 'fianliley',\n",
       " 'zdanlly',\n",
       " 'fdanlzly',\n",
       " 'fisnelly',\n",
       " 'iiaklly',\n",
       " 'fihoanlly',\n",
       " 'fiagnolly',\n",
       " 'iianally',\n",
       " 'qianllyy',\n",
       " 'kfianhlly',\n",
       " 'fiannllpy',\n",
       " 'diadlly',\n",
       " 'fbianllr',\n",
       " 'fidanljly',\n",
       " 'ffnianlly',\n",
       " 'fiwnllvy',\n",
       " 'ftajlly',\n",
       " 'rianlvly',\n",
       " 'fikanlcly',\n",
       " 'zieanlly',\n",
       " 'fihanllq',\n",
       " 'hiaqnlly',\n",
       " 'fihnllq',\n",
       " 'ffianllyu',\n",
       " 'fiaswlly',\n",
       " 'fifnlls',\n",
       " 'fianlgyly',\n",
       " 'fwiansly',\n",
       " 'fianflj',\n",
       " 'fgianllsy',\n",
       " 'fianmlluy',\n",
       " 'fmivanlly',\n",
       " 'wfiamlly',\n",
       " 'bfiawnlly',\n",
       " 'fitanhlly',\n",
       " 'fianyljly',\n",
       " 'fimanlcy',\n",
       " 'oiaenlly',\n",
       " 'fiqganlly',\n",
       " 'ffianlgly',\n",
       " 'fzanllt',\n",
       " 'fkivnlly',\n",
       " 'fwanllyw',\n",
       " 'fmankly',\n",
       " 'fiaonlzy',\n",
       " 'rjianlly',\n",
       " 'fvianslly',\n",
       " 'fianlluv',\n",
       " 'afianlcly',\n",
       " 'fiangelly',\n",
       " 'fiainllym',\n",
       " 'fianllxyz',\n",
       " 'fianllyis',\n",
       " 'fiaenllqy',\n",
       " 'lfuianlly',\n",
       " 'flitanlly',\n",
       " 'ffiapnlly',\n",
       " 'fiagloly',\n",
       " 'fianellyv',\n",
       " 'firanjly',\n",
       " 'fiinflly',\n",
       " 'fianlwyt',\n",
       " 'fiapnllay',\n",
       " 'fiagnmly',\n",
       " 'fianvully',\n",
       " 'frianlzy',\n",
       " 'mfianlnly',\n",
       " 'fiaillc',\n",
       " 'fsanhlly',\n",
       " 'fiunlyy',\n",
       " 'eianllyg',\n",
       " 'xiyanlly',\n",
       " 'fiarnslly',\n",
       " 'yivanlly',\n",
       " 'dfiknlly',\n",
       " 'fianzlfly',\n",
       " 'fzgnlly',\n",
       " 'fianity',\n",
       " 'xfpanlly',\n",
       " 'kfiarnlly',\n",
       " 'fianlpsy',\n",
       " 'fjianly',\n",
       " 'fswianlly',\n",
       " 'fianloy',\n",
       " 'ffianllyg',\n",
       " 'fiaslgy',\n",
       " 'fignllyo',\n",
       " 'fbanwlly',\n",
       " 'fimanliy',\n",
       " 'fianzlwly',\n",
       " 'fiacnolly',\n",
       " 'jnanlly',\n",
       " 'fianpllsy',\n",
       " 'fizajlly',\n",
       " 'fisatnlly',\n",
       " 'dfianllzy',\n",
       " 'xibnlly',\n",
       " 'ffibanlly',\n",
       " 'pnfianlly',\n",
       " 'fzanrlly',\n",
       " 'fhirnlly',\n",
       " 'fianlnlsy',\n",
       " 'cianwly',\n",
       " 'fianlau',\n",
       " 'fiajllny',\n",
       " 'fianllyzt',\n",
       " 'xficnlly',\n",
       " 'gfivanlly',\n",
       " 'fianlllzy',\n",
       " 'fvianjly',\n",
       " 'rmanlly',\n",
       " 'fiaelvy',\n",
       " 'fnanley',\n",
       " 'fibnllny',\n",
       " 'fyanlcy',\n",
       " 'fxanlld',\n",
       " 'fianllyda',\n",
       " 'fpannly',\n",
       " 'fiaivly',\n",
       " 'fzianllyi',\n",
       " 'fvpnlly',\n",
       " 'fianjgy',\n",
       " 'fianmlyg',\n",
       " 'fianolty',\n",
       " 'wianljy',\n",
       " 'fianalyu',\n",
       " 'dianllwy',\n",
       " 'afianllby',\n",
       " 'ftanllyc',\n",
       " 'xfianllyp',\n",
       " 'flanlfly',\n",
       " 'ninanlly',\n",
       " 'fiaqlpy',\n",
       " 'qfiinlly',\n",
       " 'fdanbly',\n",
       " 'zfirnlly',\n",
       " 'tfianily',\n",
       " 'qianll',\n",
       " 'fianzllcy',\n",
       " 'fiuanllhy',\n",
       " 'fianlnz',\n",
       " 'fieylly',\n",
       " 'rianllty',\n",
       " 'pfifnlly',\n",
       " 'ofianllyj',\n",
       " 'fxinnlly',\n",
       " 'fiailaly',\n",
       " 'fiannljy',\n",
       " 'ufianely',\n",
       " 'fzanjly',\n",
       " 'fainllz',\n",
       " 'cbanlly',\n",
       " 'fcenlly',\n",
       " 'fiallluy',\n",
       " 'pwanlly',\n",
       " 'fsivanlly',\n",
       " 'fctanlly',\n",
       " 'fjanlry',\n",
       " 'ifianllys',\n",
       " 'wfqianlly',\n",
       " 'zkanlly',\n",
       " 'fimtlly',\n",
       " 'fihnll',\n",
       " 'fiqnlsly',\n",
       " 'fiqanllc',\n",
       " 'fianlaljy',\n",
       " 'fialynlly',\n",
       " 'fiaanely',\n",
       " 'fiaqnlqly',\n",
       " 'vfiansly',\n",
       " 'fiqanllyc',\n",
       " 'hfianlzy',\n",
       " 'fianflloy',\n",
       " 'fianplply',\n",
       " 'fniandlly',\n",
       " 'tialnlly',\n",
       " 'fiahglly',\n",
       " 'ricanlly',\n",
       " 'fialnllgy',\n",
       " 'oianlyy',\n",
       " 'fianglrly',\n",
       " 'fwanrlly',\n",
       " 'fiahxlly',\n",
       " 'fioangly',\n",
       " 'vfiaelly',\n",
       " 'fbanllky',\n",
       " 'fianlwlxy',\n",
       " 'fiuanlcly',\n",
       " 'fqanllp',\n",
       " 'fianlldr',\n",
       " 'fiaplhy',\n",
       " 'franlby',\n",
       " 'fiqnlla',\n",
       " 'fineanlly',\n",
       " 'fixanllyl',\n",
       " 'fianlmlj',\n",
       " 'fnianlle',\n",
       " 'fimanrly',\n",
       " 'sianqlly',\n",
       " 'fianuld',\n",
       " 'fianliyl',\n",
       " 'fiaonglly',\n",
       " 'ffianllf',\n",
       " 'fianlkd',\n",
       " 'fhanll',\n",
       " 'qnanlly',\n",
       " 'finallty',\n",
       " 'kfiqanlly',\n",
       " 'fixally',\n",
       " 'fiawnljy',\n",
       " 'fiaclrly',\n",
       " 'fiaxlmly',\n",
       " 'fialnlyly',\n",
       " 'fianeld',\n",
       " 'yfianllyg',\n",
       " 'fianllyaj',\n",
       " 'fianably',\n",
       " 'fianleay',\n",
       " 'fiiaznlly',\n",
       " 'fijnoly',\n",
       " 'fnanlzly',\n",
       " 'ftanlls',\n",
       " 'fijahlly',\n",
       " 'fitnllys',\n",
       " 'fianllogy',\n",
       " 'fiinxlly',\n",
       " 'vfianzly',\n",
       " 'fwinanlly',\n",
       " 'fikanlvly',\n",
       " 'flanxly',\n",
       " 'fiaulnly',\n",
       " 'fianllgyi',\n",
       " 'fioanllr',\n",
       " 'fztianlly',\n",
       " 'fieanlgy',\n",
       " 'fiandlfly',\n",
       " 'fiwnllyc',\n",
       " 'fianlik',\n",
       " 'fiablkly',\n",
       " 'flpanlly',\n",
       " 'zfhanlly',\n",
       " 'fipanlwy',\n",
       " 'fhianxlly',\n",
       " 'fiavllky',\n",
       " 'fianvllm',\n",
       " 'fqianlbly',\n",
       " 'fiaonlyy',\n",
       " 'jfiantlly',\n",
       " 'fxipnlly',\n",
       " 'fiabnljly',\n",
       " 'fianbluly',\n",
       " 'fecanlly',\n",
       " 'fhiyanlly',\n",
       " 'fianlhyq',\n",
       " 'fianeoy',\n",
       " 'nianlny',\n",
       " 'fiadllw',\n",
       " 'qiaanlly',\n",
       " 'fiamnllj',\n",
       " 'fsanely',\n",
       " 'fsaknlly',\n",
       " 'fzianuly',\n",
       " 'liansly',\n",
       " 'fianlelys',\n",
       " 'fdianlfly',\n",
       " 'ifimanlly',\n",
       " 'flnally',\n",
       " 'fyifanlly',\n",
       " 'ntanlly',\n",
       " 'fganlely',\n",
       " 'fiaooly',\n",
       " 'efianelly',\n",
       " 'fiasnwly',\n",
       " 'fianlgry',\n",
       " 'fxanllyc',\n",
       " 'fijnllyn',\n",
       " 'fiaknllyo',\n",
       " 'nianlzy',\n",
       " 'rvianlly',\n",
       " 'ifianlzy',\n",
       " 'vfiaslly',\n",
       " 'fianlzply',\n",
       " 'oianolly',\n",
       " 'fiunlvy',\n",
       " 'fijanllt',\n",
       " 'fianlilz',\n",
       " 'fianpllty',\n",
       " 'fifanlsly',\n",
       " 'fiaytlly',\n",
       " 'pianxlly',\n",
       " 'fignnly',\n",
       " 'fianlylsy',\n",
       " 'fjoianlly',\n",
       " 'fzianglly',\n",
       " 'bianplly',\n",
       " 'fianzlr',\n",
       " 'fxiianlly',\n",
       " 'fiavnllyl',\n",
       " 'qmianlly',\n",
       " 'fijnlily',\n",
       " 'fianejly',\n",
       " 'fwianllyb',\n",
       " 'fganlldy',\n",
       " 'fiannlln',\n",
       " 'pfisanlly',\n",
       " 'fianpllg',\n",
       " 'fhiaslly',\n",
       " 'fzicnlly',\n",
       " 'fianlily',\n",
       " 'fsanhly',\n",
       " 'fiavllyf',\n",
       " ...}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two edit distances from input word\n",
    "edits2(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faintly', 'finally', 'finely', 'frankly'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits2(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = (known(edits0(word)) or \n",
    "              known(edits1(word)) or \n",
    "              known(edits2(word)) or \n",
    "              [word])\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"\"\"\n",
    "    Get the best correct spelling for the input word\n",
    "    \"\"\"\n",
    "    # Priority is for edit distance 0, then 1, then 2\n",
    "    # else defaults to the input word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=WORD_COUNTS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FIANLLY'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_match(match):\n",
    "    \"\"\"\n",
    "    Spell-correct word in match, \n",
    "    and preserve proper upper/lower/title case.\n",
    "    \"\"\"\n",
    "    \n",
    "    word = match.group()\n",
    "    def case_of(text):\n",
    "        \"\"\"\n",
    "        Return the case-function appropriate \n",
    "        for text: upper, lower, title, or just str.:\n",
    "            \"\"\"\n",
    "        return (str.upper if text.isupper() else\n",
    "                str.lower if text.islower() else\n",
    "                str.title if text.istitle() else\n",
    "                str)\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "    \n",
    "def correct_text_generic(text):\n",
    "    \"\"\"\n",
    "    Correct all the words within a text, \n",
    "    returning the corrected text.\n",
    "    \"\"\"\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINALLY'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "w = Word('fianlly')\n",
    "w.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('finally', 1.0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flat', 0.85), ('float', 0.15)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('flaot')\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lie'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strang'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lancaster Stemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "ls = LancasterStemmer()\n",
    "\n",
    "ls.stem('jumping'), ls.stem('jumps'), ls.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lying'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strange'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regex based stemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "rs = RegexpStemmer('ing$|s$|ed$', min=4)\n",
    "rs.stem('jumping'), rs.stem('jumps'), rs.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ly'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strange'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Languages: ('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "# Snowball Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "ss = SnowballStemmer(\"german\")\n",
    "print('Supported Languages:', SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobahn'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming on German words\n",
    "# autobahnen -> cars\n",
    "# autobahn -> car\n",
    "ss.stem('autobahnen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spring'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# springen -> jumping\n",
    "# spring -> jump\n",
    "ss.stem('springen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my system keep crash hi crash yesterday, our crash daili'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "men\n"
     ]
    }
   ],
   "source": [
    "# lemmatize nouns\n",
    "print(wnl.lemmatize('cars', 'n'))\n",
    "print(wnl.lemmatize('men', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# lemmatize verbs\n",
    "print(wnl.lemmatize('running', 'v'))\n",
    "print(wnl.lemmatize('ate', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "fancy\n"
     ]
    }
   ],
   "source": [
    "# lemmatize adjectives\n",
    "print(wnl.lemmatize('saddest', 'a'))\n",
    "print(wnl.lemmatize('fancier', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ate\n",
      "fancier\n"
     ]
    }
   ],
   "source": [
    "# ineffective lemmatization\n",
    "print(wnl.lemmatize('ate', 'n'))\n",
    "print(wnl.lemmatize('fancier', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my system keep crash ! his crash yesterday , ours crash daily'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "text = 'My system keeps crashing his crashed yesterday, ours crashes daily'\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mjack6/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False, stopwords=stopword_list):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , stopwords , computer'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"The, and, if are stopwords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = expand_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Original': \"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\",\n",
       " 'Processed': 'unveil world powerful supercomputer beat china us unveil world powerful supercomputer call summit beat previous record holder chinas sunway taihulight peak performance trillion calculation per second twice fast sunway taihulight capable trillion calculation per second summit server reportedly take size two tennis court'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Original': sample_text,\n",
    " 'Processed': normalize_corpus([sample_text])[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "venv_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
