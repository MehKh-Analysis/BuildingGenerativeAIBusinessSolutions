{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Performance Search using FAISS\n",
    "\n",
    "**pip install faiss-cpu**\n",
    "\n",
    "Source: \n",
    "\n",
    "Pratyush Khare, How to perform High-Performance Search using FAISS\n",
    "A Beginnerâ€™s Guide to FAISS, use-cases, Mathematical foundations & implementation\n",
    "\n",
    "https://kharepratyush.medium.com/how-to-perform-high-performance-search-using-faiss-da2ab12f606c\n",
    "\n",
    "Correction:\n",
    "https://sidshome.wordpress.com/2023/12/30/deep-dive-into-faiss-indexivfpq-for-vector-search/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathematical Foundations of FAISS\n",
    "\n",
    "FAISS is built on the concept of indexing, which is a method of preprocessing a dataset to make it more searchable. \n",
    "\n",
    "By grouping comparable components together, indexing reduces the number of elements that must be compared throughout the search. \n",
    "\n",
    "Product quantization (PQ) and inverted file indexing structures are the two main types of indexing structures employed in FAISS (IVF):\n",
    "\n",
    "- **Product Quantization (PQ)** is a technique for reducing the number of discrete values in high-dimensional vectors:\n",
    "\n",
    "    - The vectors are subdivided, and each subvector is quantized independently. \n",
    "\n",
    "    - This yields a vector representation that is small enough to be utilised for similarity search.\n",
    "\n",
    "- **The Inverted File (IVF)** method generates an inverted index of the dataset:\n",
    "\n",
    "    - The inverted index is a data structure that allows you to quickly discover objects in a dataset that match a specified query. \n",
    "\n",
    "    - The inverted index is constructed by dividing the dataset into a number of **small clusters** (known as **inverted lists**) and identifying each element with the cluster to which it belongs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of Each Index\n",
    "\n",
    "**LSH (Locality Sensitive Hashing):**\n",
    "Uses a hashing function that maps similar vectors to the same \"bucket\" with a high probability, allowing for fast lookups by only checking vectors within the same bucket, but can sometimes have lower precision compared to other methods. \n",
    "\n",
    "**IVF (Inverted File):**\n",
    "Divides the data space into a set of \"centroids\" and assigns each data point to its closest centroid, creating an inverted index where each centroid stores a list of associated data points, enabling faster search by only checking vectors close to the query's assigned centroid. \n",
    "\n",
    "**PQ (Product Quantization):**\n",
    "Breaks down high-dimensional vectors into smaller subvectors and quantizes each subvector separately, significantly reducing memory usage while still maintaining reasonable search accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benefits of FAISS\n",
    "\n",
    "**Efficient similarity search:** FAISS provides efficient methods for similarity search and grouping, which can handle large-scale, high-dimensional data.\n",
    "\n",
    "**Approximate nearest neighbour search:** FAISS offers an approximate closest neighbour search that delivers approximate nearest neighbours with a quality guarantee.\n",
    "\n",
    "**GPU support:** FAISS includes GPU support, which enables for further search acceleration and can greatly increase search performance on large-scale datasets.\n",
    "\n",
    "**Scalability:** FAISS is designed to be extremely scalable and capable of handling large-scale datasets including billions of components.\n",
    "\n",
    "**Flexibility:** FAISS provides a number of indexing structures, including as **LSH, IVF,** and **PQ,** that can be utilised to speed up searches and handle various types of data and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Nearest neighbour search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.394796  11.71333   12.017418  12.165682  12.351491  12.424712\n",
      "  12.530208  12.540351  12.565958  12.6878395]]\n",
      "[[688 949 630 613 945 745 644 278 595 888]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Generate a dataset of 1000 points in 100 dimensions\n",
    "X = np.random.rand(1000, 100).astype('float32')\n",
    "\n",
    "# Create an index for the dataset\n",
    "index = faiss.IndexFlatL2(100)\n",
    "\n",
    "# Add the dataset to the index\n",
    "index.add(X)\n",
    "\n",
    "# Perform a nearest neighbor search for a query vector\n",
    "query = np.random.rand(1, 100).astype('float32')\n",
    "D, I = index.search(query, k=10)\n",
    "\n",
    "# Print the distances and indices of the nearest neighbors\n",
    "print(D)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Approximate nearest neighbour search\n",
    "\n",
    "Use of the **IVFPQ** indexing structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.301941  9.339144  9.588371  9.640432  9.827304  9.891331  9.921131\n",
      "  10.078226 10.092348 10.11002 ]]\n",
      "[[530 962 204 526 819 992 143 175 868 770]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 1000 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1000 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1000 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1000 points to 256 centroids: please provide at least 9984 training points\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Generate a dataset of 1000 points in 100 dimensions\n",
    "X = np.random.rand(1000, 100).astype('float32')\n",
    "\n",
    "# Create an index for the dataset\n",
    "nlist = 100\n",
    "quantizer = faiss.IndexFlatL2(100)  # this remains the same\n",
    "# index = faiss.IndexIVFPQ(quantizer, X.shape[1], nlist, 8, 8)\n",
    "\n",
    "index = faiss.IndexIVFPQ(quantizer, X.shape[1], 4, 4, 8)\n",
    "\n",
    "# Train the index\n",
    "index.train(X)\n",
    "\n",
    "# Add the dataset to the index\n",
    "index.add(X)\n",
    "\n",
    "# Perform an approximate nearest neighbor search for a query vector\n",
    "query = np.random.rand(1, 100).astype('float32')\n",
    "D, I = index.search(query, k=10)\n",
    "\n",
    "# Print the distances and indices of the nearest neighbors\n",
    "print(D)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Real-world implementation of FAISS in an integrated machine-learning system:\n",
    "\n",
    "https://medium.com/mlearning-ai/how-do-online-marketplaces-know-your-shopping-preferences-57405d83516a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
